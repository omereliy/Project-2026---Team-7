{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NCF with Focal Loss - ML-100K Improved Experimental Design\n",
    "\n",
    "**Paper**: \"Addressing Class Imbalance in NCF with Focal Loss\" (AAMAS 2025)\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook implements improved experimental methodology to test three key hypotheses:\n",
    "\n",
    "**H1 (Efficacy)**: Focal Loss improves NeuMF performance over standard BCE loss on implicit feedback recommendation.\n",
    "\n",
    "**H2 (Robustness)**: The improvement is robust across different negative sampling ratios (1:4, 1:10, 1:50).\n",
    "\n",
    "**H3 (Mechanism)**: The focusing effect (gamma > 0) is necessary beyond simple class weighting (alpha-balanced BCE).\n",
    "\n",
    "## Improvements Over Original Design\n",
    "\n",
    "1. **Primary experiment at 1:10 sampling** (not just 1:4) - more realistic for real systems\n",
    "2. **Alpha-balanced BCE control** - isolates focusing effect from class weighting\n",
    "3. **Alpha-sampling interaction analysis** - addresses confound between alpha and sampling ratio\n",
    "4. **Robustness study** - tests across 3 sampling ratios (1:4, 1:10, 1:50)\n",
    "5. **Training dynamics tracking** - validates mechanism by analyzing loss contribution by confidence bin\n",
    "6. **Proper statistical framing** - clear hypothesis testing structure\n",
    "\n",
    "## Dataset: MovieLens 100K\n",
    "\n",
    "- 100,000 ratings from 943 users on 1,682 movies\n",
    "- Binarization: ratings >= 4 -> positive interaction\n",
    "- Leave-one-out evaluation (most recent for test)\n",
    "- Full ranking evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Cell 1: Suppress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## Cell 2: Install Dependencies\n\n**Instructions:**\n1. Run the install cell below\n2. **RESTART** the runtime (Runtime -> Restart session)\n3. Run the verification cell\n4. Continue with remaining cells"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# Install Dependencies (Part 1)\n# ============================================\n# After running this cell, RESTART the runtime, then run the next cell\n\n%pip install -q ray\n%pip install -q recbole==1.2.0\n%pip install -q kmeans-pytorch\n\n# Force numpy 1.x (required for RecBole compatibility)\n%pip uninstall -y numpy\n%pip install -q \"numpy<2\"\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RESTART REQUIRED\")\nprint(\"=\"*60)\nprint(\"Go to: Runtime -> Restart session\")\nprint(\"Then run the NEXT cell to verify installation.\")"
  },
  {
   "cell_type": "code",
   "id": "i5jpzem9ydf",
   "source": "# ============================================\n# Verify Installation (Part 2) - Run AFTER restart\n# ============================================\nimport numpy as np\nprint(f\"NumPy version: {np.__version__}\")\n\nif np.__version__.startswith(\"2.\"):\n    print(\"\\nERROR: NumPy 2.x still detected!\")\n    print(\"Try: Runtime -> Restart session -> Run this cell again\")\nelse:\n    print(\"SUCCESS: NumPy 1.x installed. Continue to next cell.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Cell 3: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Standard imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nimport os\nimport logging\nimport sys\n\n# ============================================\n# Environment Setup (Colab / Local)\n# ============================================\nif 'google.colab' in sys.modules:\n    # Clone repo if not already present\n    if not os.path.exists('/content/Project-2026---Team-7'):\n        !git clone https://github.com/omereliy/Project-2026---Team-7.git /content/Project-2026---Team-7\n    # Add experiments folder to path\n    sys.path.insert(0, '/content/Project-2026---Team-7/experiments')\n    %cd /content/Project-2026---Team-7/experiments\n    print(\"Running on Google Colab - repo cloned\")\nelse:\n    # Local: assume running from experiments folder\n    sys.path.insert(0, '.')\n    print(\"Running locally\")\n\n# PyTorch 2.6+ compatibility patch\nif not hasattr(torch, '_load_patched'):\n    _original_torch_load = torch.load\n    def _patched_torch_load(*args, **kwargs):\n        if 'weights_only' not in kwargs:\n            kwargs['weights_only'] = False\n        return _original_torch_load(*args, **kwargs)\n    torch.load = _patched_torch_load\n    torch._load_patched = True\n\nfrom focal_loss_utils import (\n    # Loss functions\n    FocalLoss, AlphaBalancedBCE,\n    # Configuration\n    get_base_config, get_neumf_config,\n    # Training functions\n    train_neumf_focal_loss, train_neumf_alpha_bce,\n    # Evaluation\n    create_comparison_table, compute_improvement,\n    # Validation\n    validate_focal_loss_implementation, demonstrate_focal_loss_effect,\n    # Alpha-sampling analysis\n    analyze_alpha_sampling_interaction, compute_effective_class_ratio,\n    get_balanced_alpha,\n    # Multi-seed experiments\n    run_multi_seed_experiment\n)\n\n# RecBole imports\nfrom recbole.quick_start import run_recbole\nfrom recbole.model.general_recommender.neumf import NeuMF\nfrom recbole.config import Config\nfrom recbole.data import create_dataset, data_preparation\nfrom recbole.trainer import Trainer\nfrom recbole.utils import init_seed, init_logger\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif torch.cuda.is_available():\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"Using CPU\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Cell 4: Focal Loss Validation Test\n",
    "\n",
    "Verify that the Focal Loss implementation is correct:\n",
    "1. FL(gamma=0, alpha=0.5) = 0.5 * BCE\n",
    "2. Higher gamma reduces loss for well-classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VALIDATION: Focal Loss Implementation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test implementation correctness\n",
    "validate_focal_loss_implementation()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMONSTRATION: Focal Loss Effect on Easy vs Hard Examples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Demonstrate focusing effect\n",
    "demo_df = demonstrate_focal_loss_effect()\n",
    "print(\"\\n\" + demo_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Easy examples (high confidence) are down-weighted by 10-100x\")\n",
    "print(\"- Hard examples (low confidence) retain most of their loss contribution\")\n",
    "print(\"- This forces the model to focus on hard-to-classify examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Cell 5: Experiment Configuration\n",
    "\n",
    "We test three negative sampling ratios:\n",
    "- **1:4** - Standard ratio used in many NCF papers\n",
    "- **1:10** - **PRIMARY EXPERIMENT** - more realistic for production systems\n",
    "- **1:50** - High negative ratio to test robustness under extreme imbalance\n",
    "\n",
    "The primary experiment uses 1:10 sampling because:\n",
    "1. It's more representative of real recommendation systems\n",
    "2. It provides stronger evidence of robustness than just testing at 1:4\n",
    "3. The class imbalance problem is more pronounced, making Focal Loss improvements more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and sampling ratios\n",
    "DATASET = 'ml-100k'\n",
    "SAMPLING_RATIOS = [4, 10, 50]  # negative samples per positive\n",
    "PRIMARY_RATIO = 10  # Main experiment uses 1:10 sampling\n",
    "\n",
    "# Focal Loss hyperparameters (from literature)\n",
    "GAMMA = 2.0  # Focusing parameter\n",
    "ALPHA = 0.25  # Class balancing weight for positives\n",
    "\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "print(f\"Negative sampling ratios: {SAMPLING_RATIOS}\")\n",
    "print(f\"Primary experiment: 1:{PRIMARY_RATIO} sampling\")\n",
    "print(f\"\\nFocal Loss hyperparameters:\")\n",
    "print(f\"  gamma = {GAMMA} (focusing parameter)\")\n",
    "print(f\"  alpha = {ALPHA} (class balancing weight for positives)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Cell 6: Configuration Setup\n",
    "\n",
    "Create configurations for each sampling ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configurations for each sampling ratio\n",
    "configs = {}\n",
    "for ratio in SAMPLING_RATIOS:\n",
    "    base = get_base_config(DATASET, device, neg_sample_num=ratio)\n",
    "    configs[ratio] = get_neumf_config(base)\n",
    "    print(f\"Configuration for 1:{ratio} sampling created\")\n",
    "\n",
    "print(\"\\nNeuMF Architecture:\")\n",
    "print(f\"  MF Embedding Size: {configs[PRIMARY_RATIO]['mf_embedding_size']}\")\n",
    "print(f\"  MLP Embedding Size: {configs[PRIMARY_RATIO]['mlp_embedding_size']}\")\n",
    "print(f\"  MLP Hidden Layers: {configs[PRIMARY_RATIO]['mlp_hidden_size']}\")\n",
    "print(f\"  Dropout: {configs[PRIMARY_RATIO]['dropout_prob']}\")\n",
    "print(f\"\\nTraining Settings:\")\n",
    "print(f\"  Max Epochs: {configs[PRIMARY_RATIO]['epochs']}\")\n",
    "print(f\"  Early Stopping Patience: {configs[PRIMARY_RATIO]['stopping_step']}\")\n",
    "print(f\"  Learning Rate: {configs[PRIMARY_RATIO]['learning_rate']}\")\n",
    "print(f\"  Batch Size: {configs[PRIMARY_RATIO]['train_batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Cell 7: Alpha-Sampling Interaction Analysis\n",
    "\n",
    "**Important Issue**: The alpha parameter and sampling ratio interact in non-obvious ways.\n",
    "\n",
    "With 1:4 sampling and alpha=0.5:\n",
    "- Each batch has 1 positive (weight: 0.5) and 4 negatives (weight: 0.5 each)\n",
    "- **Effective ratio**: (0.5 × 4) / 0.5 = 4:1 (negatives still get 4x more weight!)\n",
    "\n",
    "For balanced weighting with 1:N sampling:\n",
    "- Need alpha = N / (N + 1)\n",
    "- Example: 1:4 -> alpha = 0.8, 1:10 -> alpha = 0.909, 1:50 -> alpha = 0.98\n",
    "\n",
    "This explains why alpha=0.25 (from computer vision) may not be optimal for NCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ALPHA-SAMPLING INTERACTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analyze interaction for various alpha values\n",
    "interaction_df = analyze_alpha_sampling_interaction(\n",
    "    neg_ratios=SAMPLING_RATIOS,\n",
    "    alphas=[0.25, 0.5, 0.75]\n",
    ")\n",
    "print(\"\\n\" + interaction_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"BALANCED ALPHA VALUES (for effective ratio = 1:1)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for ratio in SAMPLING_RATIOS:\n",
    "    balanced = get_balanced_alpha(ratio)\n",
    "    actual_ratio = compute_effective_class_ratio(ALPHA, ratio)\n",
    "    print(f\"1:{ratio} sampling -> balanced alpha = {balanced:.3f}\")\n",
    "    print(f\"  Using alpha={ALPHA} -> effective ratio = {actual_ratio:.1f}:1\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Experiment 1: NeuMF-BCE Baseline (1:10 Sampling)\n",
    "\n",
    "Train standard NeuMF with Binary Cross-Entropy loss.\n",
    "\n",
    "This serves as the baseline for H1 (efficacy hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"EXPERIMENT 1: NeuMF-BCE Baseline (1:{PRIMARY_RATIO} sampling)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result_bce = run_recbole(\n",
    "    model='NeuMF',\n",
    "    dataset=DATASET,\n",
    "    config_dict=configs[PRIMARY_RATIO]\n",
    ")\n",
    "\n",
    "print(\"\\nNeuMF-BCE Results:\")\n",
    "print(f\"  Best Validation NDCG@10: {result_bce['best_valid_score']:.4f}\")\n",
    "print(f\"  Test HR@10: {result_bce['test_result'].get('hit@10', 0):.4f}\")\n",
    "print(f\"  Test NDCG@10: {result_bce['test_result'].get('ndcg@10', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Experiment 2: NeuMF with Alpha-Balanced BCE (1:10 Sampling)\n",
    "\n",
    "**NEW CONTROL EXPERIMENT**: Train NeuMF with alpha-balanced BCE (Focal Loss with gamma=0).\n",
    "\n",
    "This isolates the **focusing effect** (gamma > 0) from simple **class weighting** (alpha).\n",
    "\n",
    "- If Alpha-BCE ≈ FL: Improvement comes mainly from class weighting (H3 false)\n",
    "- If Alpha-BCE < FL: Focusing effect is necessary (H3 true)\n",
    "\n",
    "We use alpha=0.25 (same as Focal Loss) for direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"EXPERIMENT 2: NeuMF-AlphaBCE Control (1:{PRIMARY_RATIO} sampling)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Alpha-Balanced BCE: gamma=0, alpha={ALPHA}\")\n",
    "print(\"This isolates class weighting from the focusing effect.\\n\")\n",
    "\n",
    "result_alpha_bce = train_neumf_alpha_bce(\n",
    "    config_dict=configs[PRIMARY_RATIO],\n",
    "    dataset=DATASET,\n",
    "    alpha=ALPHA,\n",
    "    seed=42,\n",
    "    track_dynamics=False\n",
    ")\n",
    "\n",
    "print(\"\\nNeuMF-AlphaBCE Results:\")\n",
    "print(f\"  Best Validation NDCG@10: {result_alpha_bce['best_valid_score']:.4f}\")\n",
    "print(f\"  Test HR@10: {result_alpha_bce['test_result'].get('hit@10', 0):.4f}\")\n",
    "print(f\"  Test NDCG@10: {result_alpha_bce['test_result'].get('ndcg@10', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Experiment 3: NeuMF with Focal Loss (1:10 Sampling)\n",
    "\n",
    "Train NeuMF with Focal Loss (gamma=2.0, alpha=0.25).\n",
    "\n",
    "This is the main proposed method for H1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"EXPERIMENT 3: NeuMF-FocalLoss (1:{PRIMARY_RATIO} sampling)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Focal Loss: gamma={GAMMA}, alpha={ALPHA}\\n\")\n",
    "\n",
    "result_focal = train_neumf_focal_loss(\n",
    "    config_dict=configs[PRIMARY_RATIO],\n",
    "    dataset=DATASET,\n",
    "    gamma=GAMMA,\n",
    "    alpha=ALPHA,\n",
    "    seed=42,\n",
    "    track_dynamics=False\n",
    ")\n",
    "\n",
    "print(\"\\nNeuMF-FocalLoss Results:\")\n",
    "print(f\"  Best Validation NDCG@10: {result_focal['best_valid_score']:.4f}\")\n",
    "print(f\"  Test HR@10: {result_focal['test_result'].get('hit@10', 0):.4f}\")\n",
    "print(f\"  Test NDCG@10: {result_focal['test_result'].get('ndcg@10', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: Primary Results (1:10 Sampling)\n",
    "\n",
    "Compare BCE vs Alpha-BCE vs Focal Loss to test H1 and H3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"HYPOTHESIS TESTING: Primary Results (1:{PRIMARY_RATIO} sampling)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = create_comparison_table(\n",
    "    results_list=[result_bce, result_alpha_bce, result_focal],\n",
    "    model_names=['BCE', 'AlphaBCE', 'FocalLoss']\n",
    ")\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Compute improvements\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# H1: Focal Loss vs BCE\n",
    "print(\"\\nH1: Focal Loss vs BCE (Efficacy Hypothesis)\")\n",
    "improvements_fl_vs_bce = compute_improvement(result_bce, result_focal)\n",
    "for metric in ['ndcg@10', 'hit@10']:\n",
    "    imp = improvements_fl_vs_bce[metric]\n",
    "    print(f\"  {metric.upper()}: {imp['baseline']:.4f} -> {imp['comparison']:.4f} ({imp['pct_change']:+.2f}%)\")\n",
    "\n",
    "# H3: Focal Loss vs Alpha-BCE (Mechanism Hypothesis)\n",
    "print(\"\\nH3: Focal Loss vs Alpha-BCE (Mechanism - Focusing Effect)\")\n",
    "improvements_fl_vs_alpha = compute_improvement(result_alpha_bce, result_focal)\n",
    "for metric in ['ndcg@10', 'hit@10']:\n",
    "    imp = improvements_fl_vs_alpha[metric]\n",
    "    print(f\"  {metric.upper()}: {imp['baseline']:.4f} -> {imp['comparison']:.4f} ({imp['pct_change']:+.2f}%)\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "ndcg_fl = result_focal['test_result'].get('ndcg@10', 0)\n",
    "ndcg_bce = result_bce['test_result'].get('ndcg@10', 0)\n",
    "ndcg_alpha = result_alpha_bce['test_result'].get('ndcg@10', 0)\n",
    "\n",
    "if ndcg_fl > ndcg_bce:\n",
    "    print(\"✓ H1 SUPPORTED: Focal Loss improves over BCE\")\n",
    "else:\n",
    "    print(\"✗ H1 NOT SUPPORTED: Focal Loss does not improve over BCE\")\n",
    "\n",
    "if ndcg_fl > ndcg_alpha:\n",
    "    print(\"✓ H3 SUPPORTED: Focusing effect (gamma > 0) is necessary beyond class weighting\")\n",
    "else:\n",
    "    print(\"✗ H3 NOT SUPPORTED: Class weighting alone (Alpha-BCE) is sufficient\")\n",
    "\n",
    "if ndcg_alpha > ndcg_bce:\n",
    "    print(\"  Note: Alpha-BCE also improves over BCE, suggesting class weighting helps\")\n",
    "else:\n",
    "    print(\"  Note: Alpha-BCE does not improve over BCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Robustness Study: Multiple Sampling Ratios (H2)\n",
    "\n",
    "Test whether Focal Loss improvements are robust across different sampling ratios.\n",
    "\n",
    "We compare BCE vs Focal Loss at 1:4, 1:10, and 1:50 sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"H2: ROBUSTNESS STUDY - Multiple Sampling Ratios\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing BCE vs Focal Loss at 1:4, 1:10, and 1:50 sampling\\n\")\n",
    "\n",
    "robustness_results = {\n",
    "    'bce': {},\n",
    "    'focal': {}\n",
    "}\n",
    "\n",
    "for ratio in SAMPLING_RATIOS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Sampling Ratio: 1:{ratio}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Skip if we already trained at PRIMARY_RATIO\n",
    "    if ratio == PRIMARY_RATIO:\n",
    "        print(f\"Using existing results from primary experiment\")\n",
    "        robustness_results['bce'][ratio] = result_bce\n",
    "        robustness_results['focal'][ratio] = result_focal\n",
    "        continue\n",
    "    \n",
    "    # Train BCE\n",
    "    print(f\"\\nTraining NeuMF-BCE (1:{ratio})...\")\n",
    "    result_bce_ratio = run_recbole(\n",
    "        model='NeuMF',\n",
    "        dataset=DATASET,\n",
    "        config_dict=configs[ratio]\n",
    "    )\n",
    "    robustness_results['bce'][ratio] = result_bce_ratio\n",
    "    \n",
    "    # Train Focal Loss\n",
    "    print(f\"Training NeuMF-FocalLoss (1:{ratio})...\")\n",
    "    result_focal_ratio = train_neumf_focal_loss(\n",
    "        config_dict=configs[ratio],\n",
    "        dataset=DATASET,\n",
    "        gamma=GAMMA,\n",
    "        alpha=ALPHA,\n",
    "        seed=42,\n",
    "        track_dynamics=False\n",
    "    )\n",
    "    robustness_results['focal'][ratio] = result_focal_ratio\n",
    "    \n",
    "    # Show results\n",
    "    bce_ndcg = result_bce_ratio['test_result'].get('ndcg@10', 0)\n",
    "    fl_ndcg = result_focal_ratio['test_result'].get('ndcg@10', 0)\n",
    "    improvement = (fl_ndcg - bce_ndcg) / bce_ndcg * 100 if bce_ndcg > 0 else 0\n",
    "    \n",
    "    print(f\"\\nResults for 1:{ratio} sampling:\")\n",
    "    print(f\"  BCE NDCG@10: {bce_ndcg:.4f}\")\n",
    "    print(f\"  Focal NDCG@10: {fl_ndcg:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Robustness Study: Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ROBUSTNESS STUDY SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for ratio in SAMPLING_RATIOS:\n",
    "    bce_result = robustness_results['bce'][ratio]\n",
    "    fl_result = robustness_results['focal'][ratio]\n",
    "    \n",
    "    bce_ndcg = bce_result['test_result'].get('ndcg@10', 0)\n",
    "    fl_ndcg = fl_result['test_result'].get('ndcg@10', 0)\n",
    "    bce_hr = bce_result['test_result'].get('hit@10', 0)\n",
    "    fl_hr = fl_result['test_result'].get('hit@10', 0)\n",
    "    \n",
    "    ndcg_imp = (fl_ndcg - bce_ndcg) / bce_ndcg * 100 if bce_ndcg > 0 else 0\n",
    "    hr_imp = (fl_hr - bce_hr) / bce_hr * 100 if bce_hr > 0 else 0\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Sampling': f'1:{ratio}',\n",
    "        'BCE_NDCG@10': f'{bce_ndcg:.4f}',\n",
    "        'FL_NDCG@10': f'{fl_ndcg:.4f}',\n",
    "        'NDCG_Improvement': f'{ndcg_imp:+.2f}%',\n",
    "        'BCE_HR@10': f'{bce_hr:.4f}',\n",
    "        'FL_HR@10': f'{fl_hr:.4f}',\n",
    "        'HR_Improvement': f'{hr_imp:+.2f}%'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# H2 interpretation\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"H2 INTERPRETATION (Robustness)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "improvements = []\n",
    "for ratio in SAMPLING_RATIOS:\n",
    "    bce_ndcg = robustness_results['bce'][ratio]['test_result'].get('ndcg@10', 0)\n",
    "    fl_ndcg = robustness_results['focal'][ratio]['test_result'].get('ndcg@10', 0)\n",
    "    improvements.append(fl_ndcg > bce_ndcg)\n",
    "\n",
    "if all(improvements):\n",
    "    print(\"✓ H2 STRONGLY SUPPORTED: Focal Loss improves over BCE at ALL sampling ratios\")\n",
    "elif sum(improvements) >= 2:\n",
    "    print(\"✓ H2 PARTIALLY SUPPORTED: Focal Loss improves at most sampling ratios\")\n",
    "else:\n",
    "    print(\"✗ H2 NOT SUPPORTED: Focal Loss improvements are not robust\")\n",
    "\n",
    "print(f\"\\nFocal Loss wins at {sum(improvements)}/{len(SAMPLING_RATIOS)} sampling ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Training Dynamics Analysis\n",
    "\n",
    "**NEW ANALYSIS**: Track training dynamics to validate the Focal Loss mechanism.\n",
    "\n",
    "We track loss contribution by confidence bin to verify:\n",
    "1. Focal Loss down-weights easy examples (high confidence)\n",
    "2. Focal Loss emphasizes hard examples (low confidence)\n",
    "3. This leads to better focusing on difficult instances\n",
    "\n",
    "This provides direct evidence for the claimed mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING DYNAMICS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Re-training models with dynamics tracking enabled...\\n\")\n",
    "\n",
    "# Train BCE with dynamics tracking\n",
    "print(\"Training BCE with dynamics tracking...\")\n",
    "# Note: Standard BCE from RecBole doesn't support dynamics tracking\n",
    "# We approximate by using Alpha-BCE with alpha=0.5\n",
    "bce_dynamics = train_neumf_alpha_bce(\n",
    "    config_dict=configs[PRIMARY_RATIO],\n",
    "    dataset=DATASET,\n",
    "    alpha=0.5,  # Standard BCE\n",
    "    seed=42,\n",
    "    track_dynamics=True\n",
    ")\n",
    "\n",
    "# Train Focal Loss with dynamics tracking\n",
    "print(\"\\nTraining Focal Loss with dynamics tracking...\")\n",
    "focal_dynamics = train_neumf_focal_loss(\n",
    "    config_dict=configs[PRIMARY_RATIO],\n",
    "    dataset=DATASET,\n",
    "    gamma=GAMMA,\n",
    "    alpha=ALPHA,\n",
    "    seed=42,\n",
    "    track_dynamics=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete. Analyzing dynamics...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Training Dynamics: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING DYNAMICS: Loss by Confidence Bin\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'dynamics' in bce_dynamics and 'dynamics' in focal_dynamics:\n",
    "    bce_dyn_df = bce_dynamics['dynamics']\n",
    "    focal_dyn_df = focal_dynamics['dynamics']\n",
    "    \n",
    "    # Show final epoch dynamics\n",
    "    if len(bce_dyn_df) > 0 and len(focal_dyn_df) > 0:\n",
    "        print(\"\\nBCE - Final Epoch Loss by Confidence Bin:\")\n",
    "        print(bce_dyn_df.tail(1).to_string(index=False))\n",
    "        \n",
    "        print(\"\\nFocal Loss - Final Epoch Loss by Confidence Bin:\")\n",
    "        print(focal_dyn_df.tail(1).to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"INTERPRETATION\")\n",
    "        print(\"-\"*70)\n",
    "        print(\"Expected pattern for Focal Loss:\")\n",
    "        print(\"  - LOW loss in high confidence bins [0.8,1.0) - easy examples down-weighted\")\n",
    "        print(\"  - HIGH loss in low confidence bins [0.0,0.4) - hard examples emphasized\")\n",
    "        print(\"\\nThis validates the focusing mechanism.\")\n",
    "    else:\n",
    "        print(\"Dynamics tracking did not record data. Check model implementation.\")\n",
    "else:\n",
    "    print(\"Dynamics tracking not available. Models may not support this feature.\")\n",
    "    print(\"This is optional analysis - main results are still valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Results Summary: Full Comparison\n",
    "\n",
    "Complete results across all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset: {DATASET}\")\n",
    "print(f\"Primary Experiment: 1:{PRIMARY_RATIO} sampling\")\n",
    "print(f\"Focal Loss: gamma={GAMMA}, alpha={ALPHA}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"PRIMARY RESULTS (1:{PRIMARY_RATIO} sampling)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "primary_comparison = create_comparison_table(\n",
    "    results_list=[result_bce, result_alpha_bce, result_focal],\n",
    "    model_names=['BCE', 'AlphaBCE', 'FocalLoss']\n",
    ")\n",
    "print(\"\\n\" + primary_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ROBUSTNESS ACROSS SAMPLING RATIOS\")\n",
    "print(\"-\"*70)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPOTHESIS TESTING CONCLUSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# H1\n",
    "ndcg_fl = result_focal['test_result'].get('ndcg@10', 0)\n",
    "ndcg_bce = result_bce['test_result'].get('ndcg@10', 0)\n",
    "h1_imp = (ndcg_fl - ndcg_bce) / ndcg_bce * 100 if ndcg_bce > 0 else 0\n",
    "\n",
    "print(\"\\nH1 (Efficacy): Focal Loss improves NeuMF over BCE\")\n",
    "if ndcg_fl > ndcg_bce:\n",
    "    print(f\"  ✓ SUPPORTED: {h1_imp:+.2f}% improvement in NDCG@10\")\n",
    "else:\n",
    "    print(f\"  ✗ NOT SUPPORTED: {h1_imp:+.2f}% change in NDCG@10\")\n",
    "\n",
    "# H2\n",
    "robust_count = sum([robustness_results['focal'][r]['test_result'].get('ndcg@10', 0) > \n",
    "                    robustness_results['bce'][r]['test_result'].get('ndcg@10', 0) \n",
    "                    for r in SAMPLING_RATIOS])\n",
    "\n",
    "print(f\"\\nH2 (Robustness): Improvements are robust across sampling ratios\")\n",
    "if robust_count == len(SAMPLING_RATIOS):\n",
    "    print(f\"  ✓ STRONGLY SUPPORTED: FL wins at {robust_count}/{len(SAMPLING_RATIOS)} ratios\")\n",
    "elif robust_count >= 2:\n",
    "    print(f\"  ✓ PARTIALLY SUPPORTED: FL wins at {robust_count}/{len(SAMPLING_RATIOS)} ratios\")\n",
    "else:\n",
    "    print(f\"  ✗ NOT SUPPORTED: FL wins at only {robust_count}/{len(SAMPLING_RATIOS)} ratios\")\n",
    "\n",
    "# H3\n",
    "ndcg_alpha = result_alpha_bce['test_result'].get('ndcg@10', 0)\n",
    "h3_imp = (ndcg_fl - ndcg_alpha) / ndcg_alpha * 100 if ndcg_alpha > 0 else 0\n",
    "\n",
    "print(f\"\\nH3 (Mechanism): Focusing effect (gamma > 0) is necessary beyond class weighting\")\n",
    "if ndcg_fl > ndcg_alpha:\n",
    "    print(f\"  ✓ SUPPORTED: FL gains {h3_imp:+.2f}% over Alpha-BCE\")\n",
    "else:\n",
    "    print(f\"  ✗ NOT SUPPORTED: Alpha-BCE is sufficient ({h3_imp:+.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Optional: Grid Search for Hyperparameter Tuning\n",
    "\n",
    "**IMPORTANT**: This is computationally expensive. Only run if you want to optimize gamma and alpha.\n",
    "\n",
    "The grid search tests:\n",
    "- Multiple gamma values: [0.5, 1.0, 2.0, 3.0]\n",
    "- Multiple alpha values: [0.25, 0.5, 0.75]\n",
    "- Multiple sampling ratios: [4, 10, 50]\n",
    "\n",
    "**Uncomment to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================\n",
    "# # GRID SEARCH (OPTIONAL - COMPUTATIONALLY EXPENSIVE)\n",
    "# # ============================================\n",
    "# \n",
    "# GAMMA_VALUES = [0.5, 1.0, 2.0, 3.0]\n",
    "# ALPHA_VALUES = [0.25, 0.5, 0.75]\n",
    "# \n",
    "# print(\"=\"*70)\n",
    "# print(\"GRID SEARCH: Hyperparameter Tuning\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"Testing {len(GAMMA_VALUES)} gamma × {len(ALPHA_VALUES)} alpha × {len(SAMPLING_RATIOS)} ratios\")\n",
    "# print(f\"Total: {len(GAMMA_VALUES) * len(ALPHA_VALUES) * len(SAMPLING_RATIOS)} experiments\\n\")\n",
    "# \n",
    "# grid_results = []\n",
    "# \n",
    "# for ratio in SAMPLING_RATIOS:\n",
    "#     print(f\"\\nSampling Ratio: 1:{ratio}\")\n",
    "#     print(\"-\"*70)\n",
    "#     \n",
    "#     for gamma in GAMMA_VALUES:\n",
    "#         for alpha in ALPHA_VALUES:\n",
    "#             print(f\"Training: gamma={gamma}, alpha={alpha}\")\n",
    "#             \n",
    "#             result = train_neumf_focal_loss(\n",
    "#                 config_dict=configs[ratio],\n",
    "#                 dataset=DATASET,\n",
    "#                 gamma=gamma,\n",
    "#                 alpha=alpha,\n",
    "#                 seed=42,\n",
    "#                 track_dynamics=False\n",
    "#             )\n",
    "#             \n",
    "#             ndcg10 = result['test_result'].get('ndcg@10', 0)\n",
    "#             hr10 = result['test_result'].get('hit@10', 0)\n",
    "#             \n",
    "#             grid_results.append({\n",
    "#                 'ratio': ratio,\n",
    "#                 'gamma': gamma,\n",
    "#                 'alpha': alpha,\n",
    "#                 'ndcg@10': ndcg10,\n",
    "#                 'hit@10': hr10\n",
    "#             })\n",
    "#             \n",
    "#             print(f\"  NDCG@10: {ndcg10:.4f}, HR@10: {hr10:.4f}\")\n",
    "# \n",
    "# # Show grid search results\n",
    "# grid_df = pd.DataFrame(grid_results)\n",
    "# \n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"GRID SEARCH RESULTS\")\n",
    "# print(\"=\"*70)\n",
    "# print(\"\\n\" + grid_df.to_string(index=False))\n",
    "# \n",
    "# # Find best configuration for each ratio\n",
    "# print(\"\\n\" + \"-\"*70)\n",
    "# print(\"BEST CONFIGURATIONS PER SAMPLING RATIO\")\n",
    "# print(\"-\"*70)\n",
    "# \n",
    "# for ratio in SAMPLING_RATIOS:\n",
    "#     ratio_results = grid_df[grid_df['ratio'] == ratio]\n",
    "#     best_idx = ratio_results['ndcg@10'].idxmax()\n",
    "#     best_row = ratio_results.loc[best_idx]\n",
    "#     \n",
    "#     print(f\"\\n1:{ratio} sampling:\")\n",
    "#     print(f\"  Best: gamma={best_row['gamma']}, alpha={best_row['alpha']}\")\n",
    "#     print(f\"  NDCG@10: {best_row['ndcg@10']:.4f}\")\n",
    "#     print(f\"  HR@10: {best_row['hit@10']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}