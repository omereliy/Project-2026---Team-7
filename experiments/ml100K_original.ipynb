{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_OdLDDNiJCp"
      },
      "source": [
        "\n",
        "# NCF with Focal Loss - ML-100K Validation\n",
        "This notebook validates the implementation of Neural Collaborative Filtering (NeuMF) with Focal Loss.\n",
        "\n",
        "**Paper**: \"Addressing Class Imbalance in NCF with Focal Loss\" (AAMAS 2025)\n",
        "\n",
        "**Objective**: Compare NeuMF trained with BCE vs Focal Loss on MovieLens 100K dataset.\n",
        "\n",
        "**Success Criteria**:\n",
        "1. Both models train without errors\n",
        "2. HR@10 > 0.5 (reasonable performance)\n",
        "3. Focal Loss performs >= BCE\n",
        "4. Proper convergence curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT6TAyGciJCq"
      },
      "source": [
        "## Cell 1: Install Dependencies\n",
        "\n",
        "**Instructions:**\n",
        "1. Run the install cell below\n",
        "2. **RESTART** the runtime (Runtime -> Restart session)\n",
        "3. Run the verification cell\n",
        "4. Continue with remaining cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "810ac82a",
        "outputId": "0eae552e-438b-4f66-d69a-fa0cc35f796a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# Install Dependencies (Part 1)\n",
        "# ============================================\n",
        "# After running this cell, RESTART the runtime, then run the next cell\n",
        "\n",
        "%pip install -q ray\n",
        "%pip install -q recbole==1.2.0\n",
        "%pip install -q kmeans-pytorch\n",
        "\n",
        "# Force numpy 1.x (required for RecBole compatibility)\n",
        "%pip uninstall -y numpy\n",
        "%pip install -q \"numpy<2\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESTART REQUIRED\")\n",
        "print(\"=\"*60)\n",
        "print(\"Go to: Runtime -> Restart session\")\n",
        "print(\"Then run the NEXT cell to verify installation.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "============================================================\n",
            "RESTART REQUIRED\n",
            "============================================================\n",
            "Go to: Runtime -> Restart session\n",
            "Then run the NEXT cell to verify installation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Verify Installation (Part 2) - Run AFTER restart\n",
        "# ============================================\n",
        "import numpy as np\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "if np.__version__.startswith(\"2.\"):\n",
        "    print(\"\\nERROR: NumPy 2.x still detected!\")\n",
        "    print(\"Try: Runtime -> Restart session -> Run this cell again\")\n",
        "else:\n",
        "    print(\"SUCCESS: NumPy 1.x installed. Continue to next cell.\")"
      ],
      "metadata": {
        "id": "5d6Dnhat03WZ",
        "outputId": "baa4f7ca-2685-467a-effd-5cf8176a7cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "SUCCESS: NumPy 1.x installed. Continue to next cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWvVVbMSiJCr",
        "outputId": "32d0edab-ac0f-48a4-f8ff-410c8688c7cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 2: Imports & Environment Setup\n",
        "# ============================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "# ============================================\n",
        "# Environment Setup (Colab / Local)\n",
        "# ============================================\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Clone repo if not already present\n",
        "    if not os.path.exists('/content/Project-2026---Team-7'):\n",
        "        !git clone https://github.com/omereliy/Project-2026---Team-7.git /content/Project-2026---Team-7\n",
        "    # Add experiments folder to path and change directory\n",
        "    sys.path.insert(0, '/content/Project-2026---Team-7/experiments')\n",
        "    %cd /content/Project-2026---Team-7/experiments\n",
        "    print(\"Running on Google Colab - repo cloned\")\n",
        "else:\n",
        "    # Local: assume running from experiments folder\n",
        "    sys.path.insert(0, '.')\n",
        "    print(\"Running locally\")\n",
        "\n",
        "# ============================================\n",
        "# RecBole Fix: Patch torch.distributed.barrier for single-GPU\n",
        "# See: https://github.com/RUCAIBox/RecBole/issues/1989\n",
        "# ============================================\n",
        "if not hasattr(dist, '_barrier_patched'):\n",
        "    _original_barrier = dist.barrier\n",
        "    def _patched_barrier(*args, **kwargs):\n",
        "        if dist.is_available() and dist.is_initialized():\n",
        "            return _original_barrier(*args, **kwargs)\n",
        "        # Skip barrier if not in distributed mode\n",
        "    dist.barrier = _patched_barrier\n",
        "    dist._barrier_patched = True\n",
        "    print(\"Applied RecBole distributed fix\")\n",
        "\n",
        "# PyTorch 2.6+ compatibility patch\n",
        "if not hasattr(torch, '_load_patched'):\n",
        "    _original_torch_load = torch.load\n",
        "    def _patched_torch_load(*args, **kwargs):\n",
        "        if 'weights_only' not in kwargs:\n",
        "            kwargs['weights_only'] = False\n",
        "        return _original_torch_load(*args, **kwargs)\n",
        "    torch.load = _patched_torch_load\n",
        "    torch._load_patched = True\n",
        "\n",
        "# RecBole imports\n",
        "from recbole.quick_start import run_recbole\n",
        "from recbole.model.general_recommender.neumf import NeuMF\n",
        "from recbole.config import Config\n",
        "from recbole.data import create_dataset, data_preparation\n",
        "from recbole.trainer import Trainer\n",
        "from recbole.utils import init_seed, init_logger\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(f\"Using: CPU\")\n",
        "\n",
        "print(\"\\nImports successful!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/Project-2026---Team-7'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: '/content/Project-2026---Team-7/experiments'\n",
            "/content\n",
            "Running on Google Colab - repo cloned\n",
            "Applied RecBole distributed fix\n",
            "Using: NVIDIA L4\n",
            "\n",
            "Imports successful!\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZbxc_kTiJCs"
      },
      "source": [
        "## Cell 2: Custom Focal Loss Implementation\n",
        "\n",
        "Focal Loss formula: $FL(p_t) = -\\alpha_t (1-p_t)^\\gamma \\log(p_t)$\n",
        "\n",
        "Where:\n",
        "- $p_t$ = model's estimated probability for the ground-truth class\n",
        "- $\\gamma$ = focusing parameter (default: 2.0)\n",
        "- $\\alpha$ = class balancing weight (default: 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNr69C0iJCt",
        "outputId": "c9173e60-85f9-4d3f-d16c-b045d41233e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 3: Focal Loss Implementation\n",
        "# ============================================\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss for addressing class imbalance in recommendation systems.\n",
        "\n",
        "    Reference: Lin et al., \"Focal Loss for Dense Object Detection\", ICCV 2017\n",
        "\n",
        "    Args:\n",
        "        gamma (float): Focusing parameter. Higher values down-weight easy examples more.\n",
        "                      gamma=0 reduces to standard BCE. Default: 2.0\n",
        "        alpha (float): Class balancing weight for positive class. Default: 0.25\n",
        "        reduction (str): 'mean', 'sum', or 'none'. Default: 'mean'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: Predicted probabilities (after sigmoid), shape [batch_size]\n",
        "            targets: Ground truth labels (0 or 1), shape [batch_size]\n",
        "\n",
        "        Returns:\n",
        "            Focal loss value\n",
        "        \"\"\"\n",
        "        # Clamp for numerical stability\n",
        "        inputs = torch.clamp(inputs, min=1e-7, max=1-1e-7)\n",
        "\n",
        "        # Calculate p_t (probability of true class)\n",
        "        # p_t = p if y=1, else 1-p\n",
        "        p_t = targets * inputs + (1 - targets) * (1 - inputs)\n",
        "\n",
        "        # Calculate alpha_t (class weight)\n",
        "        # alpha_t = alpha if y=1, else 1-alpha\n",
        "        alpha_t = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n",
        "\n",
        "        # Focal loss: -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
        "        focal_weight = alpha_t * torch.pow(1 - p_t, self.gamma)\n",
        "        focal_loss = -focal_weight * torch.log(p_t)\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "\n",
        "# Verify Focal Loss implementation\n",
        "def test_focal_loss():\n",
        "    \"\"\"Test that Focal Loss with gamma=0 behaves correctly\"\"\"\n",
        "    bce_loss = nn.BCELoss()\n",
        "\n",
        "    # Test inputs\n",
        "    preds = torch.tensor([0.9, 0.1, 0.5, 0.8])\n",
        "    targets = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
        "\n",
        "    bce = bce_loss(preds, targets)\n",
        "\n",
        "    # With gamma=0 and alpha=0.5, FL = 0.5 * BCE (both classes weighted by 0.5)\n",
        "    focal_loss_gamma0 = FocalLoss(gamma=0.0, alpha=0.5)\n",
        "    fl_alpha05 = focal_loss_gamma0(preds, targets)\n",
        "\n",
        "    print(f\"BCE Loss: {bce.item():.4f}\")\n",
        "    print(f\"Focal Loss (gamma=0, alpha=0.5): {fl_alpha05.item():.4f}\")\n",
        "    print(f\"Expected (0.5 * BCE): {0.5 * bce.item():.4f}\")\n",
        "\n",
        "    # With alpha=0.5, FL should be exactly half of BCE\n",
        "    assert abs(fl_alpha05.item() - 0.5 * bce.item()) < 0.01, \"FL(gamma=0, alpha=0.5) should equal 0.5*BCE\"\n",
        "    print(\"Test 1 PASSED: FL(gamma=0, alpha=0.5) = 0.5 * BCE\")\n",
        "\n",
        "    # Test gamma effect: higher gamma should reduce loss for well-classified examples\n",
        "    focal_loss_gamma2 = FocalLoss(gamma=2.0, alpha=0.5)\n",
        "    fl_gamma2 = focal_loss_gamma2(preds, targets)\n",
        "\n",
        "    print(f\"\\nFocal Loss (gamma=2, alpha=0.5): {fl_gamma2.item():.4f}\")\n",
        "    assert fl_gamma2.item() < fl_alpha05.item(), \"Higher gamma should reduce loss\"\n",
        "    print(\"Test 2 PASSED: FL(gamma=2) < FL(gamma=0)\")\n",
        "\n",
        "    print(\"\\nFocal Loss implementation PASSED!\")\n",
        "\n",
        "test_focal_loss()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE Loss: 0.6283\n",
            "Focal Loss (gamma=0, alpha=0.5): 0.3142\n",
            "Expected (0.5 * BCE): 0.3142\n",
            "Test 1 PASSED: FL(gamma=0, alpha=0.5) = 0.5 * BCE\n",
            "\n",
            "Focal Loss (gamma=2, alpha=0.5): 0.1507\n",
            "Test 2 PASSED: FL(gamma=2) < FL(gamma=0)\n",
            "\n",
            "Focal Loss implementation PASSED!\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYZbTUOmiJCv",
        "outputId": "f4628820-d638-4065-922c-cee601150c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 4: Demonstrate Focal Loss Effect\n",
        "# ============================================\n",
        "def demonstrate_focal_loss_effect():\n",
        "    \"\"\"Show how Focal Loss down-weights easy examples\"\"\"\n",
        "    bce_loss = nn.BCELoss(reduction='none')\n",
        "    focal_loss = FocalLoss(gamma=2.0, alpha=0.25, reduction='none')\n",
        "\n",
        "    # Scenarios from the paper's toy example\n",
        "    scenarios = [\n",
        "        (\"Easy negative (model predicts 0.05 for y=0)\", torch.tensor([0.05]), torch.tensor([0.0])),\n",
        "        (\"Hard positive (model predicts 0.3 for y=1)\", torch.tensor([0.30]), torch.tensor([1.0])),\n",
        "        (\"Hard negative (model predicts 0.7 for y=0)\", torch.tensor([0.70]), torch.tensor([0.0])),\n",
        "        (\"Easy positive (model predicts 0.95 for y=1)\", torch.tensor([0.95]), torch.tensor([1.0])),\n",
        "    ]\n",
        "\n",
        "    print(\"Comparing BCE vs Focal Loss (gamma=2, alpha=0.25):\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for desc, pred, target in scenarios:\n",
        "        bce = bce_loss(pred, target).item()\n",
        "        fl = focal_loss(pred, target).item()\n",
        "        ratio = bce / fl if fl > 0 else float('inf')\n",
        "\n",
        "        print(f\"\\n{desc}\")\n",
        "        print(f\"  BCE Loss:   {bce:.4f}\")\n",
        "        print(f\"  Focal Loss: {fl:.4f}\")\n",
        "        print(f\"  BCE/FL ratio: {ratio:.1f}x (Focal Loss reduces by {ratio:.0f}x)\")\n",
        "\n",
        "demonstrate_focal_loss_effect()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing BCE vs Focal Loss (gamma=2, alpha=0.25):\n",
            "======================================================================\n",
            "\n",
            "Easy negative (model predicts 0.05 for y=0)\n",
            "  BCE Loss:   0.0513\n",
            "  Focal Loss: 0.0001\n",
            "  BCE/FL ratio: 533.3x (Focal Loss reduces by 533x)\n",
            "\n",
            "Hard positive (model predicts 0.3 for y=1)\n",
            "  BCE Loss:   1.2040\n",
            "  Focal Loss: 0.1475\n",
            "  BCE/FL ratio: 8.2x (Focal Loss reduces by 8x)\n",
            "\n",
            "Hard negative (model predicts 0.7 for y=0)\n",
            "  BCE Loss:   1.2040\n",
            "  Focal Loss: 0.4425\n",
            "  BCE/FL ratio: 2.7x (Focal Loss reduces by 3x)\n",
            "\n",
            "Easy positive (model predicts 0.95 for y=1)\n",
            "  BCE Loss:   0.0513\n",
            "  Focal Loss: 0.0000\n",
            "  BCE/FL ratio: 1600.0x (Focal Loss reduces by 1600x)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_AAnBYHiJCw"
      },
      "source": [
        "## Cell 3: Data Configuration (ML-100K)\n",
        "\n",
        "Using RecBole's built-in MovieLens 100K dataset with:\n",
        "- Binarization: ratings >= 4 → positive\n",
        "- Leave-one-out evaluation\n",
        "- 4 negatives per positive (training)\n",
        "- 99 negatives (evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYzUtqWziJCy",
        "outputId": "185a8a55-967d-49e1-82e0-064d6179b55f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 5: Base Configuration (ML-100K)\n",
        "# ============================================\n",
        "base_config = {\n",
        "    # Dataset\n",
        "    'dataset': 'ml-100k',\n",
        "    'data_path': './dataset/',\n",
        "\n",
        "    # Data preprocessing (from methodology)\n",
        "    'load_col': {'inter': ['user_id', 'item_id', 'rating', 'timestamp']},\n",
        "    'threshold': {'rating': 4},  # Binarize: ratings >= 4 are positive\n",
        "    'val_interval': {'rating': '[4,inf)'},  # Only consider ratings >= 4 as positive\n",
        "\n",
        "    # Evaluation settings (from methodology)\n",
        "    'eval_args': {\n",
        "        'split': {'LS': 'valid_and_test'},  # Leave-one-out\n",
        "        'group_by': 'user',\n",
        "        'order': 'TO',  # Temporal order (most recent for test)\n",
        "        'mode': 'full',  # Full ranking evaluation\n",
        "    },\n",
        "\n",
        "    # Training negative sampling\n",
        "    'train_neg_sample_args': {\n",
        "        'distribution': 'uniform',\n",
        "        'sample_num': 4,  # 4 negatives per positive\n",
        "        'dynamic': False,\n",
        "    },\n",
        "\n",
        "    # Evaluation settings\n",
        "    'metrics': ['Hit', 'NDCG'],\n",
        "    'topk': [5, 10, 20],\n",
        "    'valid_metric': 'NDCG@10',\n",
        "\n",
        "    # Training settings\n",
        "    'epochs': 100,\n",
        "    'stopping_step': 10,  # Early stopping patience\n",
        "    'train_batch_size': 256,\n",
        "    'eval_batch_size': 4096,\n",
        "    'learning_rate': 0.001,\n",
        "\n",
        "    # Reproducibility\n",
        "    'seed': 42,\n",
        "\n",
        "    # Device\n",
        "    'device': device,\n",
        "\n",
        "    # Logging\n",
        "    'show_progress': True,\n",
        "}\n",
        "\n",
        "print(\"Base configuration loaded.\")\n",
        "print(f\"Dataset: {base_config['dataset']}\")\n",
        "print(f\"Binarization threshold: rating >= {base_config['threshold']['rating']}\")\n",
        "print(f\"Training negatives per positive: {base_config['train_neg_sample_args']['sample_num']}\")\n",
        "print(f\"Early stopping patience: {base_config['stopping_step']} epochs\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base configuration loaded.\n",
            "Dataset: ml-100k\n",
            "Binarization threshold: rating >= 4\n",
            "Training negatives per positive: 4\n",
            "Early stopping patience: 10 epochs\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk64xWJjiJC0"
      },
      "source": [
        "## Cell 4: NeuMF with BCE (Baseline)\n",
        "\n",
        "Standard NeuMF architecture with Binary Cross-Entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oT3CKfFiJC0",
        "outputId": "44ab219e-355b-447d-d155-2140dd53cc5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 6: NeuMF-BCE Configuration\n",
        "# ============================================\n",
        "neumf_bce_config = base_config.copy()\n",
        "neumf_bce_config.update({\n",
        "    'model': 'NeuMF',\n",
        "\n",
        "    # NeuMF architecture (from methodology)\n",
        "    'mf_embedding_size': 64,\n",
        "    'mlp_embedding_size': 64,\n",
        "    'mlp_hidden_size': [128, 64, 32],\n",
        "    'dropout_prob': 0.0,\n",
        "\n",
        "    # Use default BCE loss\n",
        "    'loss_type': 'BCE',\n",
        "})\n",
        "\n",
        "print(\"NeuMF-BCE Configuration:\")\n",
        "print(f\"  MF Embedding Size: {neumf_bce_config['mf_embedding_size']}\")\n",
        "print(f\"  MLP Embedding Size: {neumf_bce_config['mlp_embedding_size']}\")\n",
        "print(f\"  MLP Hidden Layers: {neumf_bce_config['mlp_hidden_size']}\")\n",
        "print(f\"  Loss: BCE\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuMF-BCE Configuration:\n",
            "  MF Embedding Size: 64\n",
            "  MLP Embedding Size: 64\n",
            "  MLP Hidden Layers: [128, 64, 32]\n",
            "  Loss: BCE\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEj3KIibiJC1",
        "outputId": "a9a94fa9-0cdb-44b0-a692-ac17e9fac042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 7: Train NeuMF with BCE\n",
        "# ============================================\n",
        "print(\"=\"*60)\n",
        "print(\"Training NeuMF with BCE Loss\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result_bce = run_recbole(\n",
        "    model='NeuMF',\n",
        "    dataset='ml-100k',\n",
        "    config_dict=neumf_bce_config\n",
        ")\n",
        "\n",
        "# Store results\n",
        "bce_results = {\n",
        "    'model': 'NeuMF-BCE',\n",
        "    'best_valid_score': result_bce['best_valid_score'],\n",
        "    'test_result': result_bce['test_result']\n",
        "}\n",
        "\n",
        "print(\"\\nNeuMF-BCE Results:\")\n",
        "print(f\"  Best Validation NDCG@10: {result_bce['best_valid_score']:.4f}\")\n",
        "print(f\"  Test Results: {result_bce['test_result']}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-9d33ece8-8d4e-4be8-9902-09e869418684.json] will not be used in RecBole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training NeuMF with BCE Loss\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "WARNING:root:All the same value in [label] from [       user_id  item_id  timestamp  label\n",
            "0            1        1   0.509543      1\n",
            "1            2        2   0.910668      1\n",
            "2            3        3   0.272408      1\n",
            "3            4        4   0.070986      1\n",
            "4            5        5   0.244896      1\n",
            "...        ...      ...        ...    ...\n",
            "55370      424       54   0.943686      1\n",
            "55371      486      856   0.749534      1\n",
            "55372      802      334   0.412898      1\n",
            "55373      663      854   0.967611      1\n",
            "55374      701      152   0.273185      1\n",
            "\n",
            "[55375 rows x 4 columns]_feat].\n",
            "Train     0:   0%|                                                         | 0/1049 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|████████████████████| 1049/1049 [00:07<00:00, 134.72it/s, GPU RAM: 0.03 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 190.47it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     1: 100%|████████████████████| 1049/1049 [00:07<00:00, 143.44it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 208.46it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     2: 100%|████████████████████| 1049/1049 [00:07<00:00, 143.10it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 202.89it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     3: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.71it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 208.84it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     4: 100%|████████████████████| 1049/1049 [00:07<00:00, 145.37it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 206.78it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     5: 100%|████████████████████| 1049/1049 [00:07<00:00, 145.35it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 198.33it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     6: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.20it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 205.73it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     7: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.28it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 208.53it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     8: 100%|████████████████████| 1049/1049 [00:07<00:00, 141.51it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 209.68it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train     9: 100%|████████████████████| 1049/1049 [00:07<00:00, 143.71it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 209.42it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    10: 100%|████████████████████| 1049/1049 [00:07<00:00, 145.71it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 210.90it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    11: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.08it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 204.50it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    12: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.00it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 203.69it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    13: 100%|████████████████████| 1049/1049 [00:07<00:00, 144.81it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 211.94it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    14: 100%|████████████████████| 1049/1049 [00:07<00:00, 144.07it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 208.21it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    15: 100%|████████████████████| 1049/1049 [00:07<00:00, 146.13it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 210.09it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Train    16: 100%|████████████████████| 1049/1049 [00:07<00:00, 145.77it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 203.60it/s, GPU RAM: 0.05 G/22.16 G]\n",
            "Evaluate   : 100%|██████████████████████| 471/471 [00:02<00:00, 206.49it/s, GPU RAM: 0.06 G/22.16 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NeuMF-BCE Results:\n",
            "  Best Validation NDCG@10: 0.0638\n",
            "  Test Results: OrderedDict({'hit@5': 0.0786, 'hit@10': 0.1253, 'hit@20': 0.2091, 'ndcg@5': 0.0485, 'ndcg@10': 0.0637, 'ndcg@20': 0.085})\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS-ikpeDiJC1"
      },
      "source": [
        "## Cell 5: NeuMF with Focal Loss\n",
        "\n",
        "Custom NeuMF with Focal Loss (gamma=2.0, alpha=0.25).\n",
        "\n",
        "We need to create a custom model class that extends RecBole's NeuMF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va-O63BsiJC2"
      },
      "source": [
        "# ============================================\n",
        "# CELL 8: NeuMF with Focal Loss Class\n",
        "# ============================================\n",
        "# NeuMF is already imported above as direct import\n",
        "\n",
        "class NeuMF_FocalLoss(NeuMF):\n",
        "    \"\"\"\n",
        "    NeuMF model with Focal Loss instead of BCE.\n",
        "\n",
        "    This extends RecBole's NeuMF and replaces the loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, dataset, gamma=2.0, alpha=0.25):\n",
        "        super(NeuMF_FocalLoss, self).__init__(config, dataset)\n",
        "\n",
        "        # Replace BCE loss with Focal Loss\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.focal_loss = FocalLoss(gamma=gamma, alpha=alpha, reduction='mean')\n",
        "\n",
        "        print(f\"Initialized NeuMF with Focal Loss (gamma={gamma}, alpha={alpha})\")\n",
        "\n",
        "    def calculate_loss(self, interaction):\n",
        "        \"\"\"\n",
        "        Calculate Focal Loss for the given interaction.\n",
        "\n",
        "        This overrides the parent class's calculate_loss method.\n",
        "        \"\"\"\n",
        "        user = interaction[self.USER_ID]\n",
        "        item = interaction[self.ITEM_ID]\n",
        "        label = interaction[self.LABEL]\n",
        "\n",
        "        # Forward pass to get predictions\n",
        "        output = self.forward(user, item)\n",
        "\n",
        "        # Apply Focal Loss\n",
        "        loss = self.focal_loss(output, label)\n",
        "\n",
        "        return loss"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bo9IoowiJC2"
      },
      "source": [
        "# ============================================\n",
        "# CELL 9: Training Function for Focal Loss\n",
        "# ============================================\n",
        "def train_neumf_focal_loss(config_dict, gamma=2.0, alpha=0.25, seed=42):\n",
        "    \"\"\"\n",
        "    Train NeuMF with Focal Loss using RecBole's infrastructure.\n",
        "\n",
        "    Args:\n",
        "        config_dict: Configuration dictionary\n",
        "        gamma: Focal Loss focusing parameter\n",
        "        alpha: Focal Loss class balancing weight\n",
        "        seed: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with training results\n",
        "    \"\"\"\n",
        "    # Set seed\n",
        "    init_seed(seed, reproducibility=True)\n",
        "\n",
        "    # Create config\n",
        "    config = Config(model='NeuMF', dataset='ml-100k', config_dict=config_dict)\n",
        "\n",
        "    # Initialize logger\n",
        "    init_logger(config)\n",
        "    logger = logging.getLogger()\n",
        "\n",
        "    # Create dataset and dataloaders\n",
        "    dataset = create_dataset(config)\n",
        "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
        "\n",
        "    # Create model with Focal Loss\n",
        "    model = NeuMF_FocalLoss(config, dataset, gamma=gamma, alpha=alpha).to(config['device'])\n",
        "    logger.info(model)\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(config, model)\n",
        "\n",
        "    # Train\n",
        "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_result = trainer.evaluate(test_data)\n",
        "\n",
        "    return {\n",
        "        'best_valid_score': best_valid_score,\n",
        "        'best_valid_result': best_valid_result,\n",
        "        'test_result': test_result,\n",
        "        'model': model,\n",
        "        'trainer': trainer\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ych8PoOmiJC3",
        "outputId": "e3dad380-c47e-4181-9fd3-006119f2b00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 10: NeuMF-FocalLoss Configuration\n",
        "# ============================================\n",
        "neumf_fl_config = base_config.copy()\n",
        "neumf_fl_config.update({\n",
        "    'model': 'NeuMF',\n",
        "\n",
        "    # NeuMF architecture (same as BCE for fair comparison)\n",
        "    'mf_embedding_size': 64,\n",
        "    'mlp_embedding_size': 64,\n",
        "    'mlp_hidden_size': [128, 64, 32],\n",
        "    'dropout_prob': 0.0,\n",
        "})\n",
        "\n",
        "# Focal Loss hyperparameters (from methodology)\n",
        "GAMMA = 2.0  # Focusing parameter\n",
        "ALPHA = 0.25  # Class balancing weight\n",
        "\n",
        "print(\"NeuMF-FocalLoss Configuration:\")\n",
        "print(f\"  MF Embedding Size: {neumf_fl_config['mf_embedding_size']}\")\n",
        "print(f\"  MLP Embedding Size: {neumf_fl_config['mlp_embedding_size']}\")\n",
        "print(f\"  MLP Hidden Layers: {neumf_fl_config['mlp_hidden_size']}\")\n",
        "print(f\"  Focal Loss gamma: {GAMMA}\")\n",
        "print(f\"  Focal Loss alpha: {ALPHA}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuMF-FocalLoss Configuration:\n",
            "  MF Embedding Size: 64\n",
            "  MLP Embedding Size: 64\n",
            "  MLP Hidden Layers: [128, 64, 32]\n",
            "  Focal Loss gamma: 2.0\n",
            "  Focal Loss alpha: 0.25\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDu-Rp77iJC4",
        "outputId": "524dca4c-1737-49ed-da11-a0e743b9d006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 11: Train NeuMF with Focal Loss\n",
        "# ============================================\n",
        "print(\"=\"*60)\n",
        "print(f\"Training NeuMF with Focal Loss (gamma={GAMMA}, alpha={ALPHA})\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result_fl = train_neumf_focal_loss(\n",
        "    config_dict=neumf_fl_config,\n",
        "    gamma=GAMMA,\n",
        "    alpha=ALPHA,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Store results\n",
        "fl_results = {\n",
        "    'model': f'NeuMF-FL(g={GAMMA},a={ALPHA})',\n",
        "    'best_valid_score': result_fl['best_valid_score'],\n",
        "    'test_result': result_fl['test_result']\n",
        "}\n",
        "\n",
        "print(f\"\\nNeuMF-FocalLoss Results:\")\n",
        "print(f\"  Best Validation NDCG@10: {result_fl['best_valid_score']:.4f}\")\n",
        "print(f\"  Test Results: {result_fl['test_result']}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training NeuMF with Focal Loss (gamma=2.0, alpha=0.25)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-9d33ece8-8d4e-4be8-9902-09e869418684.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "WARNING:root:All the same value in [label] from [       user_id  item_id  timestamp  label\n",
            "0            1        1   0.509543      1\n",
            "1            2        2   0.910668      1\n",
            "2            3        3   0.272408      1\n",
            "3            4        4   0.070986      1\n",
            "4            5        5   0.244896      1\n",
            "...        ...      ...        ...    ...\n",
            "55370      424       54   0.943686      1\n",
            "55371      486      856   0.749534      1\n",
            "55372      802      334   0.412898      1\n",
            "55373      663      854   0.967611      1\n",
            "55374      701      152   0.273185      1\n",
            "\n",
            "[55375 rows x 4 columns]_feat].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized NeuMF with Focal Loss (gamma=2.0, alpha=0.25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NeuMF-FocalLoss Results:\n",
            "  Best Validation NDCG@10: 0.0641\n",
            "  Test Results: OrderedDict({'hit@5': 0.0679, 'hit@10': 0.1253, 'hit@20': 0.2006, 'ndcg@5': 0.0435, 'ndcg@10': 0.0619, 'ndcg@20': 0.0806})\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dSjWTeMiJC4"
      },
      "source": [
        "## Cell 6: Evaluation & Comparison\n",
        "\n",
        "Compare BCE vs Focal Loss results:\n",
        "- HR@5, HR@10, HR@20\n",
        "- NDCG@5, NDCG@10, NDCG@20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcNa6bMCiJC4",
        "outputId": "cf4bdea9-9d83-4972-e03a-7d92ec3711f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 12: Comparison Table\n",
        "# ============================================\n",
        "def create_comparison_table(bce_results, fl_results):\n",
        "    \"\"\"Create a side-by-side comparison table of BCE vs Focal Loss results\"\"\"\n",
        "\n",
        "    metrics = ['hit@5', 'hit@10', 'hit@20', 'ndcg@5', 'ndcg@10', 'ndcg@20']\n",
        "\n",
        "    data = []\n",
        "    for metric in metrics:\n",
        "        bce_val = bce_results['test_result'].get(metric, 0)\n",
        "        fl_val = fl_results['test_result'].get(metric, 0)\n",
        "        diff = fl_val - bce_val\n",
        "        pct_change = (diff / bce_val * 100) if bce_val > 0 else 0\n",
        "\n",
        "        data.append({\n",
        "            'Metric': metric.upper(),\n",
        "            'NeuMF-BCE': f'{bce_val:.4f}',\n",
        "            'NeuMF-FL': f'{fl_val:.4f}',\n",
        "            'Difference': f'{diff:+.4f}',\n",
        "            '% Change': f'{pct_change:+.2f}%'\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Display comparison\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARISON: NeuMF-BCE vs NeuMF-FocalLoss on ML-100K\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "comparison_df = create_comparison_table(bce_results, fl_results)\n",
        "print(comparison_df.to_string(index=False))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMPARISON: NeuMF-BCE vs NeuMF-FocalLoss on ML-100K\n",
            "======================================================================\n",
            " Metric NeuMF-BCE NeuMF-FL Difference % Change\n",
            "  HIT@5    0.0786   0.0679    -0.0107  -13.61%\n",
            " HIT@10    0.1253   0.1253    +0.0000   +0.00%\n",
            " HIT@20    0.2091   0.2006    -0.0085   -4.07%\n",
            " NDCG@5    0.0485   0.0435    -0.0050  -10.31%\n",
            "NDCG@10    0.0637   0.0619    -0.0018   -2.83%\n",
            "NDCG@20    0.0850   0.0806    -0.0044   -5.18%\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyyPkQY1iJC5",
        "outputId": "3d43f246-eaef-4597-f25e-e23559fb8ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 13: Validation Checks\n",
        "# ============================================\n",
        "def validate_results(bce_results, fl_results):\n",
        "    \"\"\"Check if results meet success criteria\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"VALIDATION CHECKS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check 1: Both models trained without errors\n",
        "    print(\"\\n[CHECK 1] Both models trained successfully\")\n",
        "    if bce_results['test_result'] and fl_results['test_result']:\n",
        "        print(\"  PASSED: Both models have test results\")\n",
        "    else:\n",
        "        print(\"  FAILED: One or both models failed to produce results\")\n",
        "\n",
        "    # Check 2: HR@10 > 0.5 (reasonable performance)\n",
        "    print(\"\\n[CHECK 2] Reasonable performance (HR@10 > 0.5)\")\n",
        "    bce_hr10 = bce_results['test_result'].get('hit@10', 0)\n",
        "    fl_hr10 = fl_results['test_result'].get('hit@10', 0)\n",
        "    print(f\"  BCE HR@10: {bce_hr10:.4f} {'PASSED' if bce_hr10 > 0.5 else 'BELOW THRESHOLD'}\")\n",
        "    print(f\"  FL HR@10:  {fl_hr10:.4f} {'PASSED' if fl_hr10 > 0.5 else 'BELOW THRESHOLD'}\")\n",
        "\n",
        "    # Check 3: Focal Loss >= BCE\n",
        "    print(\"\\n[CHECK 3] Focal Loss performance >= BCE\")\n",
        "    bce_ndcg10 = bce_results['test_result'].get('ndcg@10', 0)\n",
        "    fl_ndcg10 = fl_results['test_result'].get('ndcg@10', 0)\n",
        "    if fl_ndcg10 >= bce_ndcg10:\n",
        "        print(f\"  PASSED: FL NDCG@10 ({fl_ndcg10:.4f}) >= BCE NDCG@10 ({bce_ndcg10:.4f})\")\n",
        "        improvement = (fl_ndcg10 - bce_ndcg10) / bce_ndcg10 * 100\n",
        "        print(f\"  Improvement: {improvement:+.2f}%\")\n",
        "    else:\n",
        "        print(f\"  NOTE: FL NDCG@10 ({fl_ndcg10:.4f}) < BCE NDCG@10 ({bce_ndcg10:.4f})\")\n",
        "        print(\"  This may indicate need for hyperparameter tuning\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Validation complete. Review results above.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "validate_results(bce_results, fl_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "VALIDATION CHECKS\n",
            "==================================================\n",
            "\n",
            "[CHECK 1] Both models trained successfully\n",
            "  PASSED: Both models have test results\n",
            "\n",
            "[CHECK 2] Reasonable performance (HR@10 > 0.5)\n",
            "  BCE HR@10: 0.1253 BELOW THRESHOLD\n",
            "  FL HR@10:  0.1253 BELOW THRESHOLD\n",
            "\n",
            "[CHECK 3] Focal Loss performance >= BCE\n",
            "  NOTE: FL NDCG@10 (0.0619) < BCE NDCG@10 (0.0637)\n",
            "  This may indicate need for hyperparameter tuning\n",
            "\n",
            "==================================================\n",
            "Validation complete. Review results above.\n",
            "==================================================\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I4Z6bVViJC6"
      },
      "source": [
        "## Cell 7: Additional Validation - Gamma=0 Test\n",
        "\n",
        "Verify that Focal Loss with gamma=0 produces similar results to BCE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C5D3ww8iJC6",
        "outputId": "23b1f591-d07a-4823-fe40-da1d49522f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ============================================\n",
        "# CELL 14: Gamma=0 Validation Test\n",
        "# ============================================\n",
        "print(\"=\"*60)\n",
        "print(\"VALIDATION: Focal Loss with gamma=0 should approximate BCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result_fl_gamma0 = train_neumf_focal_loss(\n",
        "    config_dict=neumf_fl_config,\n",
        "    gamma=0.0,  # gamma=0 reduces to weighted BCE\n",
        "    alpha=0.5,  # alpha=0.5 for equal weighting (standard BCE)\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"\\nComparison:\")\n",
        "print(f\"  BCE NDCG@10:           {bce_results['test_result'].get('ndcg@10', 0):.4f}\")\n",
        "print(f\"  FL(gamma=0) NDCG@10:   {result_fl_gamma0['test_result'].get('ndcg@10', 0):.4f}\")\n",
        "print(f\"  FL(gamma=2) NDCG@10:   {fl_results['test_result'].get('ndcg@10', 0):.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDATION: Focal Loss with gamma=0 should approximate BCE\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-9d33ece8-8d4e-4be8-9902-09e869418684.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "WARNING:root:All the same value in [label] from [       user_id  item_id  timestamp  label\n",
            "0            1        1   0.509543      1\n",
            "1            2        2   0.910668      1\n",
            "2            3        3   0.272408      1\n",
            "3            4        4   0.070986      1\n",
            "4            5        5   0.244896      1\n",
            "...        ...      ...        ...    ...\n",
            "55370      424       54   0.943686      1\n",
            "55371      486      856   0.749534      1\n",
            "55372      802      334   0.412898      1\n",
            "55373      663      854   0.967611      1\n",
            "55374      701      152   0.273185      1\n",
            "\n",
            "[55375 rows x 4 columns]_feat].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized NeuMF with Focal Loss (gamma=0.0, alpha=0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2002399376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m result_fl_gamma0 = train_neumf_focal_loss(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mconfig_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneumf_fl_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# gamma=0 reduces to weighted BCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1078889244.py\u001b[0m in \u001b[0;36mtrain_neumf_focal_loss\u001b[0;34m(config_dict, gamma, alpha, seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mbest_valid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_valid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             train_loss = self._train_epoch(\n\u001b[0m\u001b[1;32m    440\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0minteraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/data/dataloader/general_dataloader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neg_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index, join)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/data/interaction.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mInteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FngqLmzoiJC7"
      },
      "source": [
        "## Cell 8: Summary & Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8luYhTSciJC8"
      },
      "source": [
        "# ============================================\n",
        "# CELL 15: Summary & Next Steps\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPERIMENT SUMMARY: NCF with Focal Loss on ML-100K\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nDataset: MovieLens 100K\")\n",
        "print(\"Model: NeuMF (GMF + MLP hybrid)\")\n",
        "print(\"\\nResults:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"NEXT STEPS:\")\n",
        "print(\"-\"*70)\n",
        "print(\"1. If validation passed: Proceed to full hyperparameter grid search\")\n",
        "print(\"2. Run same experiment on ML-1M dataset\")\n",
        "print(\"3. Add BPR loss comparison\")\n",
        "print(\"4. Run ablation studies (varying gamma and alpha)\")\n",
        "print(\"5. Add negative sampling ratio experiments (1:4, 1:10, 1:50)\")\n",
        "print(\"=\"*70)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhOJ07MdiJC9"
      },
      "source": [
        "---\n",
        "\n",
        "## Optional: Grid Search (Run after validation passes)\n",
        "\n",
        "Uncomment and run the cells below for full hyperparameter search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPuGf62ziJC9"
      },
      "source": [
        "# ============================================\n",
        "# CELL 16: Grid Search (Optional - Uncomment to run)\n",
        "# ============================================\n",
        "GAMMA_VALUES = [0.5, 1.0, 2.0, 3.0]\n",
        "ALPHA_VALUES = [0.25, 0.5, 0.75]\n",
        "SEEDS = list(range(10))  # 10 random seeds for statistical testing\n",
        "\n",
        "grid_search_results = []\n",
        "\n",
        "for gamma in GAMMA_VALUES:\n",
        "    for alpha in ALPHA_VALUES:\n",
        "        print(f\"\\nRunning: gamma={gamma}, alpha={alpha}\")\n",
        "\n",
        "        seed_results = []\n",
        "        for seed in SEEDS:\n",
        "            result = train_neumf_focal_loss(\n",
        "                config_dict=neumf_fl_config,\n",
        "                gamma=gamma,\n",
        "                alpha=alpha,\n",
        "                seed=seed\n",
        "            )\n",
        "            seed_results.append(result['test_result'])\n",
        "\n",
        "        # Aggregate results\n",
        "        avg_ndcg10 = np.mean([r.get('ndcg@10', 0) for r in seed_results])\n",
        "        std_ndcg10 = np.std([r.get('ndcg@10', 0) for r in seed_results])\n",
        "\n",
        "        grid_search_results.append({\n",
        "            'gamma': gamma,\n",
        "            'alpha': alpha,\n",
        "            'ndcg@10_mean': avg_ndcg10,\n",
        "            'ndcg@10_std': std_ndcg10\n",
        "        })\n",
        "\n",
        "        print(f\"  NDCG@10: {avg_ndcg10:.4f} +/- {std_ndcg10:.4f}\")\n",
        "\n",
        "# Display grid search results\n",
        "grid_df = pd.DataFrame(grid_search_results)\n",
        "print(\"\\nGrid Search Results:\")\n",
        "print(grid_df.to_string(index=False))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}