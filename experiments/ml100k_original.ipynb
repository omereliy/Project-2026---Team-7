{"cells":[{"cell_type":"markdown","metadata":{"id":"Zh5WWSXQho7V"},"source":["# NCF with Focal Loss - ML-1M Validation\n","This notebook validates the implementation of Neural Collaborative Filtering (NeuMF) with Focal Loss.\n","\n","**Paper**: \"Addressing Class Imbalance in NCF with Focal Loss\" (AAMAS 2025)\n","\n","**Objective**: Compare NeuMF trained with BCE vs Focal Loss on MovieLens 1M dataset.\n","\n","**Success Criteria**:\n","1. Both models train without errors\n","2. HR@10 \u003e 0.5 (reasonable performance)\n","3. Focal Loss performs \u003e= BCE\n","4. Proper convergence curves"]},{"cell_type":"markdown","metadata":{"id":"ozCyPU0Zho7W"},"source":["## Cell 1: Setup \u0026 Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YUqf_iWbho7W"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: numpy 1.26.4\n","Uninstalling numpy-1.26.4:\n","  Successfully uninstalled numpy-1.26.4\n","Collecting numpy==1.26.4\n","  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","Installing collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.7.2 requires numpy\u003e=2.0, but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy\u003e=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy\u003e=2, but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.35.1 requires numpy\u003e=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"776e1570c8ca4bc19506b3b976d6af89","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: recbole==1.2.0 in /usr/local/lib/python3.12/dist-packages (1.2.0)\n","Requirement already satisfied: torch\u003e=1.10.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (2.9.0+cu126)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (1.26.4)\n","Requirement already satisfied: scipy\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (1.16.3)\n","Requirement already satisfied: pandas\u003e=1.4.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (2.2.2)\n","Requirement already satisfied: tqdm\u003e=4.48.2 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (4.67.1)\n","Requirement already satisfied: colorlog==4.7.2 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (4.7.2)\n","Requirement already satisfied: colorama==0.4.4 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (0.4.4)\n","Requirement already satisfied: scikit-learn\u003e=0.23.2 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (1.6.1)\n","Requirement already satisfied: pyyaml\u003e=5.1.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (6.0.3)\n","Requirement already satisfied: tensorboard\u003e=2.5.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (2.19.0)\n","Requirement already satisfied: thop\u003e=0.1.1.post2207130030 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (0.1.1.post2209072238)\n","Requirement already satisfied: tabulate\u003e=0.8.10 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (0.9.0)\n","Requirement already satisfied: plotly\u003e=4.0.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (5.24.1)\n","Requirement already satisfied: texttable\u003e=0.9.0 in /usr/local/lib/python3.12/dist-packages (from recbole==1.2.0) (1.7.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.4.0-\u003erecbole==1.2.0) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.4.0-\u003erecbole==1.2.0) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.4.0-\u003erecbole==1.2.0) (2025.3)\n","Requirement already satisfied: tenacity\u003e=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly\u003e=4.0.0-\u003erecbole==1.2.0) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly\u003e=4.0.0-\u003erecbole==1.2.0) (25.0)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003e=0.23.2-\u003erecbole==1.2.0) (1.5.3)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003e=0.23.2-\u003erecbole==1.2.0) (3.6.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (1.76.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (3.10)\n","Requirement already satisfied: protobuf!=4.24.0,\u003e=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (5.29.5)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (75.2.0)\n","Requirement already satisfied: six\u003e1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (3.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (3.20.0)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (4.15.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (3.1.6)\n","Requirement already satisfied: fsspec\u003e=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.10.0-\u003erecbole==1.2.0) (3.5.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=1.10.0-\u003erecbole==1.2.0) (1.3.0)\n","Requirement already satisfied: markupsafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003e=2.5.0-\u003erecbole==1.2.0) (3.0.3)\n","Requirement already satisfied: kmeans-pytorch in /usr/local/lib/python3.12/dist-packages (0.3)\n","\n","NumPy version: 1.26.4\n","NumPy version OK. You can continue to the next cell.\n"]}],"source":["# ============================================\n","# CELL 1: Install Dependencies\n","# ============================================\n","# Run this cell, then RESTART the runtime before continuing!\n","\n","!pip uninstall numpy -y\n","!pip install numpy==1.26.4\n","!pip install recbole==1.2.0\n","!pip install kmeans-pytorch\n","\n","# Verify numpy version\n","import numpy as np\n","print(f\"\\nNumPy version: {np.__version__}\")\n","if np.__version__.startswith(\"2.\"):\n","    print(\"ERROR: NumPy 2.x detected! Please RESTART the runtime now.\")\n","    print(\"Go to: Runtime -\u003e Restart session\")\n","else:\n","    print(\"NumPy version OK. You can continue to the next cell.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M8EXCWbqho7W"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'ray'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3411079195.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# RecBole imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrecbole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquick_start\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_recbole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecbole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral_recommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneumf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuMF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecbole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/quick_start/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m from recbole.quick_start.quick_start import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrun_recbole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mload_data_and_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/recbole/quick_start/quick_start.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecbole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["# ============================================\n","# CELL 2: Imports\n","# ============================================\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","from collections import defaultdict\n","import os\n","import logging\n","\n","# Fix for PyTorch 2.6+ (only patch once)\n","if not hasattr(torch, '_load_patched'):\n","    _original_torch_load = torch.load\n","    def _patched_torch_load(*args, **kwargs):\n","        if 'weights_only' not in kwargs:\n","            kwargs['weights_only'] = False\n","        return _original_torch_load(*args, **kwargs)\n","    torch.load = _patched_torch_load\n","    torch._load_patched = True\n","\n","# RecBole imports\n","from recbole.quick_start import run_recbole\n","from recbole.model.general_recommender.neumf import NeuMF\n","from recbole.config import Config\n","from recbole.data import create_dataset, data_preparation\n","from recbole.trainer import Trainer\n","from recbole.utils import init_seed, init_logger\n","\n","device = torch.device('cuda')\n","print(f\"Using: {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"markdown","metadata":{"id":"pwCRS6n6ho7X"},"source":["## Cell 2: Custom Focal Loss Implementation\n","\n","Focal Loss formula: $FL(p_t) = -\\alpha_t (1-p_t)^\\gamma \\log(p_t)$\n","\n","Where:\n","- $p_t$ = model's estimated probability for the ground-truth class\n","- $\\gamma$ = focusing parameter (default: 2.0)\n","- $\\alpha$ = class balancing weight (default: 0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nR6Cwa0Mho7X"},"outputs":[],"source":["# ============================================\n","# CELL 3: Focal Loss Implementation\n","# ============================================\n","class FocalLoss(nn.Module):\n","    \"\"\"\n","    Focal Loss for addressing class imbalance in recommendation systems.\n","\n","    Reference: Lin et al., \"Focal Loss for Dense Object Detection\", ICCV 2017\n","\n","    Args:\n","        gamma (float): Focusing parameter. Higher values down-weight easy examples more.\n","                      gamma=0 reduces to standard BCE. Default: 2.0\n","        alpha (float): Class balancing weight for positive class. Default: 0.25\n","        reduction (str): 'mean', 'sum', or 'none'. Default: 'mean'\n","    \"\"\"\n","\n","    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.reduction = reduction\n","\n","    def forward(self, inputs, targets):\n","        \"\"\"\n","        Args:\n","            inputs: Predicted probabilities (after sigmoid), shape [batch_size]\n","            targets: Ground truth labels (0 or 1), shape [batch_size]\n","\n","        Returns:\n","            Focal loss value\n","        \"\"\"\n","        # Clamp for numerical stability\n","        inputs = torch.clamp(inputs, min=1e-7, max=1-1e-7)\n","\n","        # Calculate p_t (probability of true class)\n","        # p_t = p if y=1, else 1-p\n","        p_t = targets * inputs + (1 - targets) * (1 - inputs)\n","\n","        # Calculate alpha_t (class weight)\n","        # alpha_t = alpha if y=1, else 1-alpha\n","        alpha_t = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n","\n","        # Focal loss: -alpha_t * (1 - p_t)^gamma * log(p_t)\n","        focal_weight = alpha_t * torch.pow(1 - p_t, self.gamma)\n","        focal_loss = -focal_weight * torch.log(p_t)\n","\n","        if self.reduction == 'mean':\n","            return focal_loss.mean()\n","        elif self.reduction == 'sum':\n","            return focal_loss.sum()\n","        else:\n","            return focal_loss\n","\n","\n","# Verify Focal Loss implementation\n","def test_focal_loss():\n","    \"\"\"Test that Focal Loss with gamma=0 behaves correctly\"\"\"\n","    bce_loss = nn.BCELoss()\n","\n","    # Test inputs\n","    preds = torch.tensor([0.9, 0.1, 0.5, 0.8])\n","    targets = torch.tensor([1.0, 0.0, 1.0, 0.0])\n","\n","    bce = bce_loss(preds, targets)\n","\n","    # With gamma=0 and alpha=0.5, FL = 0.5 * BCE (both classes weighted by 0.5)\n","    focal_loss_gamma0 = FocalLoss(gamma=0.0, alpha=0.5)\n","    fl_alpha05 = focal_loss_gamma0(preds, targets)\n","\n","    print(f\"BCE Loss: {bce.item():.4f}\")\n","    print(f\"Focal Loss (gamma=0, alpha=0.5): {fl_alpha05.item():.4f}\")\n","    print(f\"Expected (0.5 * BCE): {0.5 * bce.item():.4f}\")\n","\n","    # With alpha=0.5, FL should be exactly half of BCE\n","    assert abs(fl_alpha05.item() - 0.5 * bce.item()) \u003c 0.01, \"FL(gamma=0, alpha=0.5) should equal 0.5*BCE\"\n","    print(\"Test 1 PASSED: FL(gamma=0, alpha=0.5) = 0.5 * BCE\")\n","\n","    # Test gamma effect: higher gamma should reduce loss for well-classified examples\n","    focal_loss_gamma2 = FocalLoss(gamma=2.0, alpha=0.5)\n","    fl_gamma2 = focal_loss_gamma2(preds, targets)\n","\n","    print(f\"\\nFocal Loss (gamma=2, alpha=0.5): {fl_gamma2.item():.4f}\")\n","    assert fl_gamma2.item() \u003c fl_alpha05.item(), \"Higher gamma should reduce loss\"\n","    print(\"Test 2 PASSED: FL(gamma=2) \u003c FL(gamma=0)\")\n","\n","    print(\"\\nFocal Loss implementation PASSED!\")\n","\n","test_focal_loss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MLDTI-2yho7X"},"outputs":[],"source":["# ============================================\n","# CELL 4: Demonstrate Focal Loss Effect\n","# ============================================\n","def demonstrate_focal_loss_effect():\n","    \"\"\"Show how Focal Loss down-weights easy examples\"\"\"\n","    bce_loss = nn.BCELoss(reduction='none')\n","    focal_loss = FocalLoss(gamma=2.0, alpha=0.25, reduction='none')\n","\n","    # Scenarios from the paper's toy example\n","    scenarios = [\n","        (\"Easy negative (model predicts 0.05 for y=0)\", torch.tensor([0.05]), torch.tensor([0.0])),\n","        (\"Hard positive (model predicts 0.3 for y=1)\", torch.tensor([0.30]), torch.tensor([1.0])),\n","        (\"Hard negative (model predicts 0.7 for y=0)\", torch.tensor([0.70]), torch.tensor([0.0])),\n","        (\"Easy positive (model predicts 0.95 for y=1)\", torch.tensor([0.95]), torch.tensor([1.0])),\n","    ]\n","\n","    print(\"Comparing BCE vs Focal Loss (gamma=2, alpha=0.25):\")\n","    print(\"=\" * 70)\n","\n","    for desc, pred, target in scenarios:\n","        bce = bce_loss(pred, target).item()\n","        fl = focal_loss(pred, target).item()\n","        ratio = bce / fl if fl \u003e 0 else float('inf')\n","\n","        print(f\"\\n{desc}\")\n","        print(f\"  BCE Loss:   {bce:.4f}\")\n","        print(f\"  Focal Loss: {fl:.4f}\")\n","        print(f\"  BCE/FL ratio: {ratio:.1f}x (Focal Loss reduces by {ratio:.0f}x)\")\n","\n","demonstrate_focal_loss_effect()"]},{"cell_type":"markdown","metadata":{"id":"fpyLxthYho7X"},"source":["## Cell 3: Data Configuration (ML-1M)\n","\n","Using RecBole's built-in MovieLens 1M dataset with:\n","- Binarization: ratings \u003e= 4 -\u003e positive\n","- Leave-one-out evaluation\n","- 4 negatives per positive (training)\n","- 99 negatives (evaluation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8BRPT2lDho7X"},"outputs":[],"source":["# ============================================\n","# CELL 5: Base Configuration (ML-1M)\n","# ============================================\n","base_config = {\n","    # Dataset\n","    'dataset': 'ml-1m',\n","    'data_path': './dataset/',\n","\n","    # Data preprocessing (from methodology)\n","    'load_col': {'inter': ['user_id', 'item_id', 'rating', 'timestamp']},\n","    'threshold': {'rating': 4},  # Binarize: ratings \u003e= 4 are positive\n","    'val_interval': {'rating': '[4,inf)'},  # Only consider ratings \u003e= 4 as positive\n","\n","    # Evaluation settings (from methodology)\n","    'eval_args': {\n","        'split': {'LS': 'valid_and_test'},  # Leave-one-out\n","        'group_by': 'user',\n","        'order': 'TO',  # Temporal order (most recent for test)\n","        'mode': 'full',  # Full ranking evaluation\n","    },\n","\n","    # Training negative sampling\n","    'train_neg_sample_args': {\n","        'distribution': 'uniform',\n","        'sample_num': 4,  # 4 negatives per positive\n","        'dynamic': False,\n","    },\n","\n","    # Evaluation settings\n","    'metrics': ['Hit', 'NDCG'],\n","    'topk': [5, 10, 20],\n","    'valid_metric': 'NDCG@10',\n","\n","    # Training settings\n","    'epochs': 100,\n","    'stopping_step': 10,  # Early stopping patience\n","    'train_batch_size': 256,\n","    'eval_batch_size': 4096,\n","    'learning_rate': 0.001,\n","\n","    # Reproducibility\n","    'seed': 42,\n","\n","    # Device\n","    'device': device,\n","\n","    # Logging\n","    'show_progress': True,\n","}\n","\n","print(\"Base configuration loaded.\")\n","print(f\"Dataset: {base_config['dataset']}\")\n","print(f\"Binarization threshold: rating \u003e= {base_config['threshold']['rating']}\")\n","print(f\"Training negatives per positive: {base_config['train_neg_sample_args']['sample_num']}\")\n","print(f\"Early stopping patience: {base_config['stopping_step']} epochs\")"]},{"cell_type":"markdown","metadata":{"id":"DFBHNIMRho7X"},"source":["## Cell 4: NeuMF with BCE (Baseline)\n","\n","Standard NeuMF architecture with Binary Cross-Entropy loss."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N3hIITNdho7X"},"outputs":[],"source":["# ============================================\n","# CELL 6: NeuMF-BCE Configuration\n","# ============================================\n","neumf_bce_config = base_config.copy()\n","neumf_bce_config.update({\n","    'model': 'NeuMF',\n","\n","    # NeuMF architecture (from methodology)\n","    'mf_embedding_size': 64,\n","    'mlp_embedding_size': 64,\n","    'mlp_hidden_size': [128, 64, 32],\n","    'dropout_prob': 0.0,\n","\n","    # Use default BCE loss\n","    'loss_type': 'BCE',\n","})\n","\n","print(\"NeuMF-BCE Configuration:\")\n","print(f\"  MF Embedding Size: {neumf_bce_config['mf_embedding_size']}\")\n","print(f\"  MLP Embedding Size: {neumf_bce_config['mlp_embedding_size']}\")\n","print(f\"  MLP Hidden Layers: {neumf_bce_config['mlp_hidden_size']}\")\n","print(f\"  Loss: BCE\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OVTAnMB_ho7X"},"outputs":[],"source":["# ============================================\n","# CELL 7: Train NeuMF with BCE\n","# ============================================\n","print(\"=\"*60)\n","print(\"Training NeuMF with BCE Loss\")\n","print(\"=\"*60)\n","\n","result_bce = run_recbole(\n","    model='NeuMF',\n","    dataset='ml-1m',\n","    config_dict=neumf_bce_config\n",")\n","\n","# Store results\n","bce_results = {\n","    'model': 'NeuMF-BCE',\n","    'best_valid_score': result_bce['best_valid_score'],\n","    'test_result': result_bce['test_result']\n","}\n","\n","print(\"\\nNeuMF-BCE Results:\")\n","print(f\"  Best Validation NDCG@10: {result_bce['best_valid_score']:.4f}\")\n","print(f\"  Test Results: {result_bce['test_result']}\")"]},{"cell_type":"markdown","metadata":{"id":"S3jDMGgHho7X"},"source":["## Cell 5: NeuMF with Focal Loss\n","\n","Custom NeuMF with Focal Loss (gamma=2.0, alpha=0.25).\n","\n","We need to create a custom model class that extends RecBole's NeuMF."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"C-aW1Mm4ho7X"},"outputs":[],"source":["# ============================================\n","# CELL 8: NeuMF with Focal Loss Class\n","# ============================================\n","# NeuMF is already imported above as direct import\n","\n","class NeuMF_FocalLoss(NeuMF):\n","    \"\"\"\n","    NeuMF model with Focal Loss instead of BCE.\n","\n","    This extends RecBole's NeuMF and replaces the loss function.\n","    \"\"\"\n","\n","    def __init__(self, config, dataset, gamma=2.0, alpha=0.25):\n","        super(NeuMF_FocalLoss, self).__init__(config, dataset)\n","\n","        # Replace BCE loss with Focal Loss\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.focal_loss = FocalLoss(gamma=gamma, alpha=alpha, reduction='mean')\n","\n","        print(f\"Initialized NeuMF with Focal Loss (gamma={gamma}, alpha={alpha})\")\n","\n","    def calculate_loss(self, interaction):\n","        \"\"\"\n","        Calculate Focal Loss for the given interaction.\n","\n","        This overrides the parent class's calculate_loss method.\n","        \"\"\"\n","        user = interaction[self.USER_ID]\n","        item = interaction[self.ITEM_ID]\n","        label = interaction[self.LABEL]\n","\n","        # Forward pass to get predictions\n","        output = self.forward(user, item)\n","\n","        # Apply Focal Loss\n","        loss = self.focal_loss(output, label)\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HZKjaoESho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 9: Training Function for Focal Loss\n","# ============================================\n","def train_neumf_focal_loss(config_dict, gamma=2.0, alpha=0.25, seed=42):\n","    \"\"\"\n","    Train NeuMF with Focal Loss using RecBole's infrastructure.\n","\n","    Args:\n","        config_dict: Configuration dictionary\n","        gamma: Focal Loss focusing parameter\n","        alpha: Focal Loss class balancing weight\n","        seed: Random seed for reproducibility\n","\n","    Returns:\n","        Dictionary with training results\n","    \"\"\"\n","    # Set seed\n","    init_seed(seed, reproducibility=True)\n","\n","    # Create config\n","    config = Config(model='NeuMF', dataset='ml-1m', config_dict=config_dict)\n","\n","    # Initialize logger\n","    init_logger(config)\n","    logger = logging.getLogger()\n","\n","    # Create dataset and dataloaders\n","    dataset = create_dataset(config)\n","    train_data, valid_data, test_data = data_preparation(config, dataset)\n","\n","    # Create model with Focal Loss\n","    model = NeuMF_FocalLoss(config, dataset, gamma=gamma, alpha=alpha).to(config['device'])\n","    logger.info(model)\n","\n","    # Create trainer\n","    trainer = Trainer(config, model)\n","\n","    # Train\n","    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n","\n","    # Evaluate on test set\n","    test_result = trainer.evaluate(test_data)\n","\n","    return {\n","        'best_valid_score': best_valid_score,\n","        'best_valid_result': best_valid_result,\n","        'test_result': test_result,\n","        'model': model,\n","        'trainer': trainer\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"36GwUSrTho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 10: NeuMF-FocalLoss Configuration\n","# ============================================\n","neumf_fl_config = base_config.copy()\n","neumf_fl_config.update({\n","    'model': 'NeuMF',\n","\n","    # NeuMF architecture (same as BCE for fair comparison)\n","    'mf_embedding_size': 64,\n","    'mlp_embedding_size': 64,\n","    'mlp_hidden_size': [128, 64, 32],\n","    'dropout_prob': 0.0,\n","})\n","\n","# Focal Loss hyperparameters (from methodology)\n","GAMMA = 2.0  # Focusing parameter\n","ALPHA = 0.25  # Class balancing weight\n","\n","print(\"NeuMF-FocalLoss Configuration:\")\n","print(f\"  MF Embedding Size: {neumf_fl_config['mf_embedding_size']}\")\n","print(f\"  MLP Embedding Size: {neumf_fl_config['mlp_embedding_size']}\")\n","print(f\"  MLP Hidden Layers: {neumf_fl_config['mlp_hidden_size']}\")\n","print(f\"  Focal Loss gamma: {GAMMA}\")\n","print(f\"  Focal Loss alpha: {ALPHA}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Z9sxYjXBho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 11: Train NeuMF with Focal Loss\n","# ============================================\n","print(\"=\"*60)\n","print(f\"Training NeuMF with Focal Loss (gamma={GAMMA}, alpha={ALPHA})\")\n","print(\"=\"*60)\n","\n","result_fl = train_neumf_focal_loss(\n","    config_dict=neumf_fl_config,\n","    gamma=GAMMA,\n","    alpha=ALPHA,\n","    seed=42\n",")\n","\n","# Store results\n","fl_results = {\n","    'model': f'NeuMF-FL(g={GAMMA},a={ALPHA})',\n","    'best_valid_score': result_fl['best_valid_score'],\n","    'test_result': result_fl['test_result']\n","}\n","\n","print(f\"\\nNeuMF-FocalLoss Results:\")\n","print(f\"  Best Validation NDCG@10: {result_fl['best_valid_score']:.4f}\")\n","print(f\"  Test Results: {result_fl['test_result']}\")"]},{"cell_type":"markdown","metadata":{"id":"jSlZgHe0ho7Y"},"source":["## Cell 6: Evaluation \u0026 Comparison\n","\n","Compare BCE vs Focal Loss results:\n","- HR@5, HR@10, HR@20\n","- NDCG@5, NDCG@10, NDCG@20"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bFSuPnQnho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 12: Comparison Table\n","# ============================================\n","def create_comparison_table(bce_results, fl_results):\n","    \"\"\"Create a side-by-side comparison table of BCE vs Focal Loss results\"\"\"\n","\n","    metrics = ['hit@5', 'hit@10', 'hit@20', 'ndcg@5', 'ndcg@10', 'ndcg@20']\n","\n","    data = []\n","    for metric in metrics:\n","        bce_val = bce_results['test_result'].get(metric, 0)\n","        fl_val = fl_results['test_result'].get(metric, 0)\n","        diff = fl_val - bce_val\n","        pct_change = (diff / bce_val * 100) if bce_val \u003e 0 else 0\n","\n","        data.append({\n","            'Metric': metric.upper(),\n","            'NeuMF-BCE': f'{bce_val:.4f}',\n","            'NeuMF-FL': f'{fl_val:.4f}',\n","            'Difference': f'{diff:+.4f}',\n","            '% Change': f'{pct_change:+.2f}%'\n","        })\n","\n","    df = pd.DataFrame(data)\n","    return df\n","\n","# Display comparison\n","print(\"=\"*70)\n","print(\"COMPARISON: NeuMF-BCE vs NeuMF-FocalLoss on ML-1M\")\n","print(\"=\"*70)\n","\n","comparison_df = create_comparison_table(bce_results, fl_results)\n","print(comparison_df.to_string(index=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"llvZyWP_ho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 13: Validation Checks\n","# ============================================\n","def validate_results(bce_results, fl_results):\n","    \"\"\"Check if results meet success criteria\"\"\"\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"VALIDATION CHECKS\")\n","    print(\"=\"*50)\n","\n","    # Check 1: Both models trained without errors\n","    print(\"\\n[CHECK 1] Both models trained successfully\")\n","    if bce_results['test_result'] and fl_results['test_result']:\n","        print(\"  PASSED: Both models have test results\")\n","    else:\n","        print(\"  FAILED: One or both models failed to produce results\")\n","\n","    # Check 2: HR@10 \u003e 0.5 (reasonable performance)\n","    print(\"\\n[CHECK 2] Reasonable performance (HR@10 \u003e 0.5)\")\n","    bce_hr10 = bce_results['test_result'].get('hit@10', 0)\n","    fl_hr10 = fl_results['test_result'].get('hit@10', 0)\n","    print(f\"  BCE HR@10: {bce_hr10:.4f} {'PASSED' if bce_hr10 \u003e 0.5 else 'BELOW THRESHOLD'}\")\n","    print(f\"  FL HR@10:  {fl_hr10:.4f} {'PASSED' if fl_hr10 \u003e 0.5 else 'BELOW THRESHOLD'}\")\n","\n","    # Check 3: Focal Loss \u003e= BCE\n","    print(\"\\n[CHECK 3] Focal Loss performance \u003e= BCE\")\n","    bce_ndcg10 = bce_results['test_result'].get('ndcg@10', 0)\n","    fl_ndcg10 = fl_results['test_result'].get('ndcg@10', 0)\n","    if fl_ndcg10 \u003e= bce_ndcg10:\n","        print(f\"  PASSED: FL NDCG@10 ({fl_ndcg10:.4f}) \u003e= BCE NDCG@10 ({bce_ndcg10:.4f})\")\n","        improvement = (fl_ndcg10 - bce_ndcg10) / bce_ndcg10 * 100\n","        print(f\"  Improvement: {improvement:+.2f}%\")\n","    else:\n","        print(f\"  NOTE: FL NDCG@10 ({fl_ndcg10:.4f}) \u003c BCE NDCG@10 ({bce_ndcg10:.4f})\")\n","        print(\"  This may indicate need for hyperparameter tuning\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"Validation complete. Review results above.\")\n","    print(\"=\"*50)\n","\n","validate_results(bce_results, fl_results)"]},{"cell_type":"markdown","metadata":{"id":"5hKA3La0ho7Y"},"source":["## Cell 7: Additional Validation - Gamma=0 Test\n","\n","Verify that Focal Loss with gamma=0 produces similar results to BCE."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WYRiJibcho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 14: Gamma=0 Validation Test\n","# ============================================\n","print(\"=\"*60)\n","print(\"VALIDATION: Focal Loss with gamma=0 should approximate BCE\")\n","print(\"=\"*60)\n","\n","result_fl_gamma0 = train_neumf_focal_loss(\n","    config_dict=neumf_fl_config,\n","    gamma=0.0,  # gamma=0 reduces to weighted BCE\n","    alpha=0.5,  # alpha=0.5 for equal weighting (standard BCE)\n","    seed=42\n",")\n","\n","print(f\"\\nComparison:\")\n","print(f\"  BCE NDCG@10:           {bce_results['test_result'].get('ndcg@10', 0):.4f}\")\n","print(f\"  FL(gamma=0) NDCG@10:   {result_fl_gamma0['test_result'].get('ndcg@10', 0):.4f}\")\n","print(f\"  FL(gamma=2) NDCG@10:   {fl_results['test_result'].get('ndcg@10', 0):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"6Ow69rwIho7Y"},"source":["## Cell 8: Summary \u0026 Next Steps"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9cvWa8Xcho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 15: Summary \u0026 Next Steps\n","# ============================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"EXPERIMENT SUMMARY: NCF with Focal Loss on ML-1M\")\n","print(\"=\"*70)\n","\n","print(\"\\nDataset: MovieLens 1M\")\n","print(\"Model: NeuMF (GMF + MLP hybrid)\")\n","print(\"\\nResults:\")\n","print(comparison_df.to_string(index=False))\n","\n","print(\"\\n\" + \"-\"*70)\n","print(\"NEXT STEPS:\")\n","print(\"-\"*70)\n","print(\"1. If validation passed: Proceed to full hyperparameter grid search\")\n","print(\"2. Run same experiment on larger datasets (Amazon, Yelp)\")\n","print(\"3. Add BPR loss comparison\")\n","print(\"4. Run ablation studies (varying gamma and alpha)\")\n","print(\"5. Add negative sampling ratio experiments (1:4, 1:10, 1:50)\")\n","print(\"=\"*70)"]},{"cell_type":"markdown","metadata":{"id":"9DYP2Gzvho7Y"},"source":["---\n","\n","## Optional: Grid Search (Run after validation passes)\n","\n","Uncomment and run the cells below for full hyperparameter search."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6AK7rL-aho7Y"},"outputs":[],"source":["# ============================================\n","# CELL 16: Grid Search (Optional - Uncomment to run)\n","# ============================================\n","GAMMA_VALUES = [0.5, 1.0, 2.0, 3.0]\n","ALPHA_VALUES = [0.25, 0.5, 0.75]\n","SEEDS = list(range(10))  # 10 random seeds for statistical testing\n","\n","grid_search_results = []\n","\n","for gamma in GAMMA_VALUES:\n","    for alpha in ALPHA_VALUES:\n","        print(f\"\\nRunning: gamma={gamma}, alpha={alpha}\")\n","\n","        seed_results = []\n","        for seed in SEEDS:\n","            result = train_neumf_focal_loss(\n","                config_dict=neumf_fl_config,\n","                gamma=gamma,\n","                alpha=alpha,\n","                seed=seed\n","            )\n","            seed_results.append(result['test_result'])\n","\n","        # Aggregate results\n","        avg_ndcg10 = np.mean([r.get('ndcg@10', 0) for r in seed_results])\n","        std_ndcg10 = np.std([r.get('ndcg@10', 0) for r in seed_results])\n","\n","        grid_search_results.append({\n","            'gamma': gamma,\n","            'alpha': alpha,\n","            'ndcg@10_mean': avg_ndcg10,\n","            'ndcg@10_std': std_ndcg10\n","        })\n","\n","        print(f\"  NDCG@10: {avg_ndcg10:.4f} +/- {std_ndcg10:.4f}\")\n","\n","# Display grid search results\n","grid_df = pd.DataFrame(grid_search_results)\n","print(\"\\nGrid Search Results:\")\n","print(grid_df.to_string(index=False))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}